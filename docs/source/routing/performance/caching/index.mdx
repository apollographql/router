---
title: Caching in Apollo Router
subtitle: Accelerate query retrieval with in-memory and distributed caching
description: Accelerate query retrieval for your federated graph with in-memory and distributed caching in Apollo Router.
---

Apollo Router supports multiple caching strategies, including in-memory caching, distributed caching with Redis, and response caching, that allow you to reduce redundant subgraph requests and improve query latency. 

## In-memory caching

By default, the router stores in its in-memory cache to improve performance:

- Generated query plans
- Automatic persisted queries (APQ)
- Introspection responses

You can configure certain caching behaviors for generated query plans and APQ (but not introspection responses). For details, see in-memory caching in the Apollo Router.

Learn more about [in-memory caching](/graphos/routing/performance/caching/in-memory).

## Distributed caching

You can configure a Redis-backed distributed cache that enables multiple router instances to share cached values. Those instances can share a Redis-backed cache for their query plans and automatic persisted queries (APQ). If any of your router instances caches a particular value, all of your instances can look up that value to significantly improve responsiveness.

Learn more about [distributed caching](/graphos/routing/performance/caching/distributed).

## Response caching

Response caching speeds up graph data retrieval by storing portions of GraphQL responses at the entity and operation level. Using Redis, the router caches subgraph responses and serves them from cache when the same entities are requestedâ€”even across different operations and clients. This reduces load on your subgraphs and backend services.

You can configure cache expiration with TTL or active invalidation via API, and customize caching behavior per subgraph or operation.

[Learn more about response caching](/graphos/routing/performance/caching/response-caching).
