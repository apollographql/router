---
title: Response caching for the GraphOS Router
subtitle: Configure Redis-backed caching for subgraph responses
description: Response caching for GraphOS Router with GraphOS Enterprise. Cache and reuse individual entities and root fields across queries.
minVersion: Router v2.8.0
releaseStage: preview
---

<PlanRequired plans={["Free", "Developer", "Standard", "Enterprise"]}>

Rate limits apply on the Free plan.
Performance pricing applies on Developer and Standard plans.
Developer and Standard plans require Router v2.6.0 or later.

</PlanRequired>

Learn how the GraphOS Router can cache subgraph query responses using Redis to improve your query latency for entities in the supergraph.

## Quickstart

Follow this guide to enable and add a minimal configuration for response caching in the GraphOS Router.

### Prerequisites

To use response caching in the GraphOS Router, you must set up:

- A Redis instance or cluster that your router instances can communicate with
- A [GraphOS Enterprise plan](https://www.apollographql.com/pricing/) that [connects your router to GraphOS](/router/configuration/overview/#environment-variables).

### Configure router for response caching

In `router.yaml`, configure `preview_response_cache`:
- Enable response caching globally.
- Configure Redis using the same conventions described in [distributed caching](/router/configuration/distributed-caching#redis-url-configuration).
- Configure response caching per subgraph, with overrides per subgraph for disabling response caching and TTL.

For example:

```yaml title="router.yaml"
# Enable response caching globally
preview_response_cache:
  enabled: true
  debug: true # Enable the ability to return debugging data for caching debugger. It's better to not enable this in production.
  invalidation:
    listen: 0.0.0.0:4000
    path: /invalidation
  subgraph:
    all:
      enabled: true
      # Configure Redis for all subgraphs
      redis:
        urls: ["redis://localhost:6379"]
      invalidation:
        enabled: true
        shared_key: ${env.INVALIDATION_SHARED_KEY} # Use environment variable INVALIDATION_SHARED_KEY
```


### Identify what data to cache

Links to telemetry page with metrics and dashboard screenshots and studio insights

### Schema integration
XXX
Demo with @cacheTag and @cacheControl directive

### Subgraph response integration
Demo with cache-control response header and subgraph response extensions

### Invalidation
XXX

================================











### Configure time to live (TTL)

Besides configuring a global TTL for all the entries in Redis, the GraphOS Router also honors the [`Cache-Control` header](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control) returned with the subgraph response. It generates a `Cache-Control` header for the client response by aggregating the TTL information from all response parts.
A TTL has to be configured for all subgraphs using entity caching, either defined in the per subgraph configuration or inherited from the global configuration, in case the subgraph returns a `Cache-Control` header without a `max-age`.

### Customize Redis cache key

If you need to store data for a particular request in different cache entries, you can configure the cache key through the `apollo_entity_cache::key` context entry.

This entry contains an object with the `all` field to affect all subgraph requests under one client request, and fields named after subgraph operation names to affect individual subgraph queries. The field's value can be any valid JSON value (object, string, etc).

```json
{
    "all": 1,
    "subgraph_operation1": "key1",
    "subgraph_operation2": {
      "data": "key2"
    }
}
```


#### Observability

Invalidation requests are instrumented with the following metrics:
- `apollo.router.operations.entity.invalidation.event` - counter triggered when a batch of invalidation requests is received. It has a label `origin` that can be either `endpoint` or `extensions`.
- `apollo.router.operations.entity.invalidation.entry` - counter measuring how many entries are removed per `DEL` call. It has a label `origin` that can be either `endpoint` or `extensions`, and a label `subgraph.name` with the name of the receiving subgraph.
- `apollo.router.cache.invalidation.keys` - histogram measuring the number of keys that were removed from Redis per invalidation request.
- `apollo.router.cache.invalidation.duration` - histogram measuring the time spent handling one invalidation request.

Invalidation requests are also reported under the following spans:
- `cache.invalidation.batch` - span covering the processing of a list of invalidation requests. It has a label `origin` that can be either `endpoint` or `extensions`.
- `cache.invalidation.request` - span covering the processing of a single invalidation request.

#### Failure cases

Entity caching will greatly reduce traffic to subgraphs. Should there be an availability issue with a Redis cache, this could cause traffic to subgraphs to increase to a level where infrastructure becomes overwhelmed. To avoid such issues, the router should be configured with [rate limiting for subgraph requests](/router/configuration/traffic-shaping/#rate-limiting-1) to avoid overwhelming the subgraphs. It could also be paired with [subgraph query deduplication](/router/configuration/traffic-shaping/#query-deduplication) to further reduce traffic.

#### Scalability and performance

The scalability and performance of entity cache invalidation is based on its implementation with the Redis [`SCAN` command](https://redis.io/docs/latest/commands/scan/). The `SCAN` command provides a cursor for iterating over the entire key space and returns a list of keys matching a pattern. When executing an invalidation request, the router first runs a series of `SCAN` calls and then it runs [`DEL`](https://redis.io/docs/latest/commands/del/) calls for any matching keys.

The time complexity of a single invalidation request grows linearly with the number of entries, as each entry requires `SCAN` to iterate over. The router can also execute multiple invalidation requests simultaneously. This lowers latency but might increase the load on Redis instances.

To help tune invalidation performance and scalability, you should benchmark the ratio of the invalidation rate against the number of entries that will be recorded. If it's too low, you can tune it with the following:
- Increase the number of pooled Redis connections.
- Increasing the `SCAN` count option. This shouldn't be too large, with 1000 as a generally reasonable value, because larger values will reduce the operation throughput of the Redis instance.
- Use separate Redis instances for some subgraphs.

### Private information caching

A subgraph can return a response with the header `Cache-Control: private`, indicating that it contains user-personalized data. Although this usually forbids intermediate servers from storing data, the router may be able to recognize different users and store their data in different parts of the cache.

To set up private information caching, you can configure the `private_id` option. `private_id` is a string pointing at a field in the request context that contains data used to recognize users (for example, user id, or `sub` claim in JWT).

As an example, if you are using the router's JWT authentication plugin, you can first configure the `private_id` option in the `accounts` subgraph to point to the `user_id` key in context, then use a Rhai script to set that key from the JWT's `sub` claim:

```yaml title="router.yaml"
preview_entity_cache:
  enabled: true
  subgraph:
    all:
      enabled: true
      redis:
        urls: ["redis://..."]
    subgraphs:
      accounts:
        private_id: "user_id"
authentication:
  router:
    jwt:
      jwks:
        - url: https://auth-server/jwks.json
```

```rhai title="main.rhai"
fn supergraph_service(service) {
  let request_callback = |request| {
    let claims = request.context[Router.APOLLO_AUTHENTICATION_JWT_CLAIMS];

    if claims != () {
      let private_id = claims["sub"];
      request.context["user_id"] = private_id;
    }
  };

  service.map_request(request_callback);
}
```

The router implements the following sequence to determine whether a particular query returns private data:

- Upon seeing a query for the first time, the router requests the cache as if it were a public-only query.
- When the subgraph returns the response with private data, the router recognizes it and stores the data in a user-specific part of the cache.
- The router stores the query in a list of known queries with private data.
- When the router subsequently sees a known query:
  - If the private id isn't provided, the router doesn't interrogate the cache, but it instead transmits the subgraph response directly.
  - If the private id is provided, the router queries the part of the cache for the current user and checks the subgraph if nothing is available.

### Observability

The router supports a [`cache` selector](/router/configuration/telemetry/instrumentation/selectors#subgraph) in telemetry for the subgraph service. The selector returns the number of cache hits or misses by an entity for a subgraph request.

## Spans

You can add a new attribute on the subgraph span for the number of cache hits. For example:

```yaml title="router.yaml"
telemetry:
  instrumentation:
    spans:
      subgraph:
        attributes:
          cache.hit:
            cache: hit
```

## Metrics

The router provides the `telemetry.instrumentation.instruments.cache` instrument to enable cache metrics:

```yaml title="router.yaml"
telemetry:
  instrumentation:
    instruments:
      cache: # Cache instruments configuration
        apollo.router.operations.entity.cache: # A counter which counts the number of cache hit and miss for subgraph requests
          attributes:
            graphql.type.name: true # Include the entity type name. default: false
            subgraph.name: # Custom attributes to include the subgraph name in the metric
              subgraph_name: true
            supergraph.operation.name: # Add custom attribute to display the supergraph operation name
              supergraph_operation_name: string
            # You can add more custom attributes using subgraph selectors
```

You can use custom instruments to create metrics for the subgraph service. The following example creates a custom instrument to generate a histogram that measures the subgraph request duration when there's at least one cache hit for the "inventory" subgraph:

```yaml title="router.yaml"
telemetry:
  instrumentation:
    instruments:
      subgraph:
        only_cache_hit_on_subgraph_inventory:
          type: histogram
          value: duration
          unit: hit
          description: histogram of subgraph request duration when we have cache hit on subgraph inventory
          condition:
            all:
            - eq:
              - subgraph_name: true # subgraph selector
              - inventory
            - gt: # If the number of cache hit is greater than 0
              - cache: hit
              # entity_type: Product # Here you could also only check for the entity type Product, it's `all` by default if we don't specify this config.
              - 0

```


## Implementation notes

### Cache-Control header requirement

The Router currently cannot know which types or fields should be cached, so it requires the subgraph to set a `Cache-Control` header in its response to indicate that it should be stored.

### Responses with errors not cached

To prevent transient errors from affecting the cache for a long duration, subgraph responses with errors are not cached.

### Cached entities with unavailable subgraph

If some entities were obtained from the cache, but the subgraphs that provided them are unavailable, the router will return a response with the cached entities, and the other entities nullified (schema permitting), along with an error message for the nullified entities.

### Authorization and entity caching

When used alongside the router's [authorization directives](/router/configuration/authorization), cache entries are separated by authorization context. If a query contains fields that need a specific scope, the requests providing that scope have different cache entries from those not providing the scope. This means that data requiring authorization can still be safely cached and even shared across users, without needing invalidation when a user's roles change because their requests are automatically directed to a different part of the cache.

### Schema updates and entity caching

On schema updates, the router ensures that queries unaffected by the changes keep their cache entries. Queries with affected fields need to be cached again to ensure the router doesn't serve invalid data from before the update.
