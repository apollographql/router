---
title: Subgraph entity caching for the Apollo Router
subtitle: Redis-backed caching for entities
description: Subgraph entity caching for Apollo Router with GraphOS Enterprise. Cache and reuse individual entities across queries
---

<EnterpriseFeature />

The Apollo Router can cache, in Redis, data returned by subgraph queries, split per entity. This means that the same client query performed by different clients, with different arguments, will be able to share data from subgraph responses.

## Prerequisites

To use this feature:

- You must have a Redis cluster (or single instance) that your router instances can communicate with.
- You must have a [GraphOS Enterprise plan](https://www.apollographql.com/pricing/) and [connect your router to GraphOS](./overview/#environment-variables).

## How it works

As an example, we might have a query requesting:
- the cart of the current user
- for each product in the cart:
    - its description and price
    - its availability in inventory

If we were caching the entire client response, we would have to store it with a short time to live, because the cart data can change often, and inventory has to be up to date. That cache cannot be shared between users, because the cart is personal. We would also duplicate a lot of data between responses, because a lot of the products might appear in multiple carts.

With entity caching, we are able to:
- store each product's description and price separately, with a large TTL
- for each query, some of the products might already be in cache, so we will send smaller queries to the subgraph, or even no query at all
- share the product cache between all users
- cache the cart per user, with a small amount of data
- cache inventory data with a low TTL or even not cache it at all

### Details

To prevent transient errors from affecting the cache on a long period, responses with errors are not cached.

When used along with the Router's authorization directives, cache entries are separated by authorization context. If a query contains fields that need a specific scope, the requests providing that scope and the ones without will have different cache entries. This means that data requiring authorization can still be safely cached, and even shared across users, and will not need invalidation when a user's roles change, as their queries will be directed to a different part of the cache automatically.

On schema updates, the Router makes sure that queries unaffected by the changes will keep their cache entries. Queries with affected fields will need to be cached again, making sure that we don't serve invalid data from the cache after the update.

Invalidation is not yet implemented, but planned.

## Configuration

It is setup as follows:

```yaml title="router.yaml"
experimental_entity_cache:
  enabled: true

  redis:
    urls: ["redis://..."]
    timeout: 5ms # Optional, by default: 2ms
    ttl: 24h # Optional, by default no expiration

  subgraphs:
    accounts:
      enabled: false # disable for a specific subgraph
    reviews:
      ttl: 120s # overrides the global TTL
```

The `redis` section follows the same convention as in [distributed caching](./distributed-caching).

## Time to live

We can configure a global TTL for all the entries in Redis.

The Apollo Router will also honor the `Cache-Control` header returned with the subgraph response, and generate a `Cache-Control` header for the client response by aggregating the TTL information from all the response parts.

## Cache key manipulation

If we need to store data for a particular query in different cache entries, the cache key can be influenced through the `apollo_entity_cache::key` context entry. This entry contains an object with the fields `all` to affect all subgraph queries under one client query, and fields named after subgr aph operation names to affect individual subgraph queries. The value of the field can be any valid JSON value (object, string, etc).

```json
{
    "all": 1,
    "subgraph_operation1": "key1",
    "subgraph_operation2": {
      "data": "key2"
    }
}

```