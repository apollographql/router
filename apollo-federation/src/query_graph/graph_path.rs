use std::cmp::Ordering;
use std::collections::BinaryHeap;
use std::collections::HashSet;
use std::fmt::Display;
use std::fmt::Formatter;
use std::fmt::Write;
use std::hash::Hash;
use std::ops::Deref;
use std::sync::atomic;
use std::sync::Arc;

use apollo_compiler::ast::Value;
use apollo_compiler::executable::DirectiveList;
use apollo_compiler::schema::ExtendedType;
use apollo_compiler::schema::Name;
use apollo_compiler::NodeStr;
use indexmap::IndexMap;
use indexmap::IndexSet;
use petgraph::graph::EdgeIndex;
use petgraph::graph::NodeIndex;
use petgraph::visit::EdgeRef;

use crate::error::FederationError;
use crate::indented_display::write_indented_lines;
use crate::indented_display::State as IndentedFormatter;
use crate::is_leaf_type;
use crate::link::federation_spec_definition::get_federation_spec_definition_from_subgraph;
use crate::link::graphql_definition::BooleanOrVariable;
use crate::link::graphql_definition::DeferDirectiveArguments;
use crate::link::graphql_definition::OperationConditional;
use crate::link::graphql_definition::OperationConditionalKind;
use crate::query_graph::condition_resolver::ConditionResolution;
use crate::query_graph::condition_resolver::ConditionResolver;
use crate::query_graph::condition_resolver::UnsatisfiedConditionReason;
use crate::query_graph::path_tree::OpPathTree;
use crate::query_graph::QueryGraph;
use crate::query_graph::QueryGraphEdgeTransition;
use crate::query_graph::QueryGraphNodeType;
use crate::query_plan::operation::Field;
use crate::query_plan::operation::FieldData;
use crate::query_plan::operation::HasSelectionKey;
use crate::query_plan::operation::InlineFragment;
use crate::query_plan::operation::InlineFragmentData;
use crate::query_plan::operation::RebaseErrorHandlingOption;
use crate::query_plan::operation::SelectionId;
use crate::query_plan::operation::SelectionKey;
use crate::query_plan::operation::SelectionSet;
use crate::query_plan::FetchDataPathElement;
use crate::query_plan::QueryPathElement;
use crate::query_plan::QueryPlanCost;
use crate::schema::position::AbstractTypeDefinitionPosition;
use crate::schema::position::CompositeTypeDefinitionPosition;
use crate::schema::position::InterfaceFieldDefinitionPosition;
use crate::schema::position::ObjectTypeDefinitionPosition;
use crate::schema::position::OutputTypeDefinitionPosition;
use crate::schema::position::TypeDefinitionPosition;
use crate::schema::ValidFederationSchema;

/// An immutable path in a query graph.
///
/// A "path" here is mostly understood in the graph-theoretical sense of the term, i.e. as "a
/// connected series of edges"; a `GraphPath` is generated by traversing a query graph.
///
/// However, as query graph edges may have conditions, a `GraphPath` also records, for each edge it
/// is composed of, the set of paths (an `OpPathTree` in practice) that were taken to fulfill each
/// edge's conditions (when an edge has one).
///
/// Additionally, for each edge of the path, a `GraphPath` records the "trigger" that made the
/// traversal take that edge. In practice, the "trigger" can be seen as a way to decorate a path
/// with some additional metadata for each element of the path. In practice, that trigger is used in
/// 2 main ways (corresponding to our 2 main query graph traversals):
/// - For composition validation, the traversal of the federated query graph is driven by other
///   transitions into the supergraph API query graph (essentially, composition validation is about
///   finding, for every path in supergraph API query graph, a "matching" traversal of the federated
///   query graph). In that case, for the graph paths we build on the federated query graph, the
///   "trigger" will be one of the edge transitions from the supergraph API query graph (which,
///   granted, will be fairly similar to the one of the edge we're taking in the federated query
///   graph; in practice, triggers are more useful in the query planning case).
/// - For query planning, the traversal of the federated query graph is driven by the elements of
///   the query we are planning. Which means that the "trigger" for taking an edge in this case will
///   be an operation element (or `None`). See the specialized `OpGraphPath` that is defined for this
///   use case.
///
/// Lastly, some `GraphPath`s can actually encode `None` edges: this is used during query planning
/// in the (rare) case where the query we plan for has an inline fragment spread without type
/// condition (or a "useless" one, i.e. one that doesn't restrict the possible types anymore than
/// they already were) but with some directives. In that case, we want to preserve the information
/// about the directive (to properly rebuild query plans later) but it doesn't correspond to taking
/// any edges, so we add a `None` edge and use the trigger to store the fragment spread.
///
/// Regarding type parameters:
/// - `TTrigger`: The type of the path's "triggers", metadata that can associated to each element
///   of the path (see above for more details).
/// - `TEdge`: The type of the edge. Either `Option<EdgeIndex>` (meaning that the path may have a
///   `None` edge) or `never` (the path cannot have `None` edges).
// PORT_NOTE: The JS codebase also parameterized whether the head of the path was a root node, but
// in the Rust code we don't have a distinguished type for that case. We instead check this at
// runtime (at the callsites that require root nodes). This means the `RootPath` type in the
// JS codebase is replaced with this one.
#[derive(Clone)]
pub(crate) struct GraphPath<TTrigger, TEdge>
where
    TTrigger: Eq + Hash,
    Arc<TTrigger>: Into<GraphPathTrigger>,
    TEdge: Copy + Into<Option<EdgeIndex>>,
    EdgeIndex: Into<TEdge>,
{
    /// The query graph of which this is a path.
    graph: Arc<QueryGraph>,
    /// The node at which the path starts. This should be the head of the first non-`None` edge in
    /// the path if such edge exists, but if there are only `None` edges (or if there are zero
    /// edges), this will still exist (and the head and tail of the path will be the same).
    head: NodeIndex,
    /// The node at which the path stops. This should be the tail of the last non-`None` edge in the
    /// path if such edge exists, but if there are only `None` edges (or if there are zero edges),
    /// this will still exist (and the head and tail of the path will be the same).
    pub(crate) tail: NodeIndex,
    /// The edges composing the path.
    edges: Vec<TEdge>,
    /// The triggers associated to each edge in the path.
    edge_triggers: Vec<Arc<TTrigger>>,
    /// For each edge in the path, if the edge has conditions, the set of paths that fulfill that
    /// condition.
    ///
    /// Note that no matter which kind of traversal we are doing (composition or query planning),
    /// fulfilling the conditions is always driven by the conditions themselves, and since
    /// conditions are a GraphQL result set, the resulting set of paths are an `OpGraphPath` (and
    /// since they start at the edge's head node, we use the `OpPathTree` representation for that
    /// set of paths).
    edge_conditions: Vec<Option<Arc<OpPathTree>>>,
    /// Information about the last subgraph-entering edge in this path, which is used to eliminate
    /// some non-optimal paths. (This is reset when encountering a `@defer` application.)
    last_subgraph_entering_edge_info: Option<SubgraphEnteringEdgeInfo>,
    /// As part of an optimization, we keep track of when one path "overrides" other paths by
    /// creating an ID, and storing that ID in the paths to track the "overrides" relationship (not
    /// to be confused with the `@override` directive, which is completely separate).
    ///
    /// This array stores the IDs associated with this path.
    own_path_ids: Arc<IndexSet<OverrideId>>,
    /// This array stores the IDs of paths that override this one. (See docs for `own_path_ids` for
    /// more info).
    overriding_path_ids: Arc<IndexSet<OverrideId>>,
    /// Names of all the possible runtime types the tail of the path can be.
    runtime_types_of_tail: Arc<IndexSet<ObjectTypeDefinitionPosition>>,
    /// If the last edge in the `edges` array was a `DownCast` transition, then the runtime types
    /// before that edge.
    runtime_types_before_tail_if_last_is_cast: Option<Arc<IndexSet<ObjectTypeDefinitionPosition>>>,
    /// If the trigger of the last edge in the `edges` array was an operation element with a
    /// `@defer` application, then the arguments of that application.
    defer_on_tail: Option<DeferDirectiveArguments>,
}

impl<TTrigger, TEdge> std::fmt::Debug for GraphPath<TTrigger, TEdge>
where
    TTrigger: Eq + Hash,
    Arc<TTrigger>: Into<GraphPathTrigger>,
    TEdge: Copy + Into<Option<EdgeIndex>>,
    EdgeIndex: Into<TEdge>,
    // In addition to the bounds of the GraphPath struct, also require Debug:
    TTrigger: std::fmt::Debug,
    TEdge: std::fmt::Debug,
{
    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
        let Self {
            graph: _, // skip
            head,
            tail,
            edges,
            edge_triggers,
            edge_conditions,
            last_subgraph_entering_edge_info,
            own_path_ids,
            overriding_path_ids,
            runtime_types_of_tail,
            runtime_types_before_tail_if_last_is_cast,
            defer_on_tail,
        } = self;

        f.debug_struct("GraphPath")
            .field("head", head)
            .field("tail", tail)
            .field("edges", edges)
            .field("edge_triggers", edge_triggers)
            .field("edge_conditions", edge_conditions)
            .field(
                "last_subgraph_entering_edge_info",
                last_subgraph_entering_edge_info,
            )
            .field("own_path_ids", own_path_ids)
            .field("overriding_path_ids", overriding_path_ids)
            .field("runtime_types_of_tail", runtime_types_of_tail)
            .field(
                "runtime_types_before_tail_if_last_is_cast",
                runtime_types_before_tail_if_last_is_cast,
            )
            .field("defer_on_tail", defer_on_tail)
            .finish_non_exhaustive()
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Hash, derive_more::From)]
pub(crate) enum GraphPathTrigger {
    Op(Arc<OpGraphPathTrigger>),
    Transition(Arc<QueryGraphEdgeTransition>),
}

#[derive(Debug, Clone)]
pub(crate) struct SubgraphEnteringEdgeInfo {
    /// The index within the `edges` array.
    index: usize,
    /// The cost of resolving the conditions for this edge.
    conditions_cost: QueryPlanCost,
}

/// Wrapper for an override ID, which indicates a relationship between a group of `OpGraphPath`s
/// where one "overrides" the others in the group.
///
/// Note that we shouldn't add `derive(Serialize, Deserialize)` to this without changing the types
/// to be something like UUIDs.
#[derive(Clone, Copy, Debug, Eq, PartialEq, Hash)]
pub(crate) struct OverrideId(usize);

/// Global storage for the counter used to allocate `OverrideId`s.
static NEXT_OVERRIDE_ID: atomic::AtomicUsize = atomic::AtomicUsize::new(1);

impl OverrideId {
    fn new() -> Self {
        // atomically increment global counter
        Self(NEXT_OVERRIDE_ID.fetch_add(1, atomic::Ordering::AcqRel))
    }
}

/// The item type for [`GraphPath::iter`]
pub(crate) type GraphPathItem<'path, TTrigger, TEdge> =
    (TEdge, &'path Arc<TTrigger>, &'path Option<Arc<OpPathTree>>);

/// A `GraphPath` whose triggers are operation elements (essentially meaning that the path has been
/// guided by a GraphQL operation).
// PORT_NOTE: As noted in the docs for `GraphPath`, we omit a type parameter for the root node,
// whose constraint is instead checked at runtime. This means the `OpRootPath` type in the JS
// codebase is replaced with this one.
pub(crate) type OpGraphPath = GraphPath<OpGraphPathTrigger, Option<EdgeIndex>>;

#[derive(Debug, Clone, PartialEq, Eq, Hash, derive_more::From)]
pub(crate) enum OpGraphPathTrigger {
    OpPathElement(OpPathElement),
    Context(OpGraphPathContext),
}

impl Display for OpGraphPathTrigger {
    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
        match self {
            OpGraphPathTrigger::OpPathElement(ele) => ele.fmt(f),
            OpGraphPathTrigger::Context(ctx) => ctx.fmt(f),
        }
    }
}

/// A path of operation elements within a GraphQL operation.
#[derive(Debug, Clone, PartialEq, Eq, Hash, Default)]
pub(crate) struct OpPath(pub(crate) Vec<Arc<OpPathElement>>);

impl Deref for OpPath {
    type Target = [Arc<OpPathElement>];
    fn deref(&self) -> &Self::Target {
        &self.0
    }
}

impl std::fmt::Display for OpPath {
    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
        for (i, element) in self.0.iter().enumerate() {
            if i > 0 {
                write!(f, "::")?;
            }
            match element.deref() {
                OpPathElement::Field(field) => write!(f, "{field}")?,
                OpPathElement::InlineFragment(fragment) => write!(f, "{fragment}")?,
            }
        }
        Ok(())
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Hash, derive_more::From)]
pub(crate) enum OpPathElement {
    Field(Field),
    InlineFragment(InlineFragment),
}

impl HasSelectionKey for OpPathElement {
    fn key(&self) -> SelectionKey {
        match self {
            OpPathElement::Field(field) => field.key(),
            OpPathElement::InlineFragment(fragment) => fragment.key(),
        }
    }
}

impl OpPathElement {
    pub(crate) fn directives(&self) -> &Arc<DirectiveList> {
        match self {
            OpPathElement::Field(field) => &field.data().directives,
            OpPathElement::InlineFragment(inline_fragment) => &inline_fragment.data().directives,
        }
    }

    pub(crate) fn schema(&self) -> &ValidFederationSchema {
        match self {
            OpPathElement::Field(field) => field.schema(),
            OpPathElement::InlineFragment(fragment) => fragment.schema(),
        }
    }

    pub(crate) fn is_terminal(&self) -> Result<bool, FederationError> {
        match self {
            OpPathElement::Field(field) => field.data().is_leaf(),
            OpPathElement::InlineFragment(_) => Ok(false),
        }
    }

    pub(crate) fn sibling_typename(&self) -> Option<&Name> {
        match self {
            OpPathElement::Field(field) => field.sibling_typename(),
            OpPathElement::InlineFragment(_) => None,
        }
    }

    pub(crate) fn parent_type_position(&self) -> CompositeTypeDefinitionPosition {
        match self {
            OpPathElement::Field(field) => field.data().field_position.parent(),
            OpPathElement::InlineFragment(inline) => inline.data().parent_type_position.clone(),
        }
    }

    pub(crate) fn sub_selection_type_position(
        &self,
    ) -> Result<Option<CompositeTypeDefinitionPosition>, FederationError> {
        match self {
            OpPathElement::Field(field) => Ok(field.data().output_base_type()?.try_into().ok()),
            OpPathElement::InlineFragment(inline) => Ok(Some(inline.data().casted_type())),
        }
    }

    pub(crate) fn extract_operation_conditionals(
        &self,
    ) -> Result<Vec<OperationConditional>, FederationError> {
        let mut conditionals = vec![];
        // PORT_NOTE: We explicitly use the order `Skip` and `Include` here, to align with the order
        // used by the JS codebase.
        for kind in [
            OperationConditionalKind::Skip,
            OperationConditionalKind::Include,
        ] {
            let directive_name: &'static str = (&kind).into();
            if let Some(application) = self.directives().get(directive_name) {
                let Some(arg) = application.argument_by_name("if") else {
                    return Err(FederationError::internal(format!(
                        "@{} missing required argument \"if\"",
                        directive_name
                    )));
                };
                let value = match arg.deref() {
                    Value::Variable(variable_name) => {
                        BooleanOrVariable::Variable(variable_name.clone())
                    }
                    Value::Boolean(boolean) => BooleanOrVariable::Boolean(*boolean),
                    _ => {
                        return Err(FederationError::internal(format!(
                            "@{} has invalid value {} for argument \"if\"",
                            directive_name,
                            arg.serialize().no_indent()
                        )));
                    }
                };
                conditionals.push(OperationConditional { kind, value })
            }
        }
        Ok(conditionals)
    }

    pub(crate) fn with_updated_directives(&self, directives: DirectiveList) -> OpPathElement {
        match self {
            OpPathElement::Field(field) => {
                OpPathElement::Field(field.with_updated_directives(directives))
            }
            OpPathElement::InlineFragment(inline_fragment) => {
                OpPathElement::InlineFragment(inline_fragment.with_updated_directives(directives))
            }
        }
    }

    pub(crate) fn as_path_element(&self) -> Option<FetchDataPathElement> {
        match self {
            OpPathElement::Field(field) => Some(field.as_path_element()),
            OpPathElement::InlineFragment(inline_fragment) => inline_fragment.as_path_element(),
        }
    }

    pub(crate) fn defer_directive_args(&self) -> Option<DeferDirectiveArguments> {
        match self {
            OpPathElement::Field(_) => None, // @defer cannot be on field at the moment
            OpPathElement::InlineFragment(inline_fragment) => inline_fragment
                .data()
                .defer_directive_arguments()
                .ok()
                .flatten(),
        }
    }

    /// Returns this fragment element but with any @defer directive on it removed.
    ///
    /// This method will return `None` if, upon removing @defer, the fragment has no conditions nor
    /// any remaining applied directives (meaning that it carries no information whatsoever and can be
    /// ignored).
    pub(crate) fn without_defer(&self) -> Option<Self> {
        match self {
            Self::Field(_) => Some(self.clone()), // unchanged
            Self::InlineFragment(inline_fragment) => {
                let updated_directives: DirectiveList = inline_fragment
                    .data()
                    .directives
                    .get_all("defer")
                    .cloned()
                    .collect();
                if inline_fragment.data().type_condition_position.is_none()
                    && updated_directives.is_empty()
                {
                    return None;
                }
                if inline_fragment.data().directives.len() == updated_directives.len() {
                    Some(self.clone())
                } else {
                    // PORT_NOTE: We won't need to port `this.copyAttachementsTo(updated);` line here
                    // since `with_updated_directives` clones the whole `self` and thus sibling
                    // type names should be copied as well.
                    Some(self.with_updated_directives(updated_directives))
                }
            }
        }
    }

    pub(crate) fn rebase_on(
        &self,
        parent_type: &CompositeTypeDefinitionPosition,
        schema: &ValidFederationSchema,
        error_handling: RebaseErrorHandlingOption,
    ) -> Result<Option<OpPathElement>, FederationError> {
        match self {
            OpPathElement::Field(field) => field
                .rebase_on(parent_type, schema, error_handling)
                .map(|val| val.map(Into::into)),
            OpPathElement::InlineFragment(inline) => inline
                .rebase_on(parent_type, schema, error_handling)
                .map(|val| val.map(Into::into)),
        }
    }
}

impl Display for OpPathElement {
    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
        match self {
            OpPathElement::Field(field) => field.fmt(f),
            OpPathElement::InlineFragment(inline_fragment) => inline_fragment.fmt(f),
        }
    }
}

impl From<Field> for OpGraphPathTrigger {
    fn from(value: Field) -> Self {
        OpPathElement::from(value).into()
    }
}

impl From<InlineFragment> for OpGraphPathTrigger {
    fn from(value: InlineFragment) -> Self {
        OpPathElement::from(value).into()
    }
}

/// Records, as we walk a path within a GraphQL operation, important directives encountered
/// (currently `@include` and `@skip` with their conditions).
#[derive(Debug, Clone, PartialEq, Eq, Hash, Default)]
pub(crate) struct OpGraphPathContext {
    /// A list of conditionals (e.g. `[{ kind: Include, value: true}, { kind: Skip, value: $foo }]`)
    /// in the reverse order in which they were applied (so the first element is the inner-most
    /// applied include/skip).
    conditionals: Arc<Vec<OperationConditional>>,
}

impl OpGraphPathContext {
    pub(crate) fn with_context_of(
        &self,
        operation_element: &OpPathElement,
    ) -> Result<OpGraphPathContext, FederationError> {
        let mut new_context = self.clone();
        if operation_element.directives().is_empty() {
            return Ok(new_context);
        }

        let new_conditionals = operation_element.extract_operation_conditionals()?;
        if !new_conditionals.is_empty() {
            Arc::make_mut(&mut new_context.conditionals).extend(new_conditionals);
        }
        Ok(new_context)
    }

    pub(crate) fn is_empty(&self) -> bool {
        self.conditionals.is_empty()
    }

    pub(crate) fn iter(&self) -> impl Iterator<Item = &OperationConditional> {
        self.conditionals.iter()
    }
}

impl Display for OpGraphPathContext {
    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
        write!(f, "[")?;
        let mut iter = self.conditionals.iter();
        if let Some(cond) = iter.next() {
            write!(f, "@{}(if: {})", cond.kind, cond.value)?;
            iter.try_for_each(|cond| write!(f, ", @{}(if: {})", cond.kind, cond.value))?;
        }
        write!(f, "]")
    }
}

/// A vector of graph paths that are being considered simultaneously by the query planner as an
/// option for a path within a GraphQL operation. These arise since the edge to take in a query
/// graph may depend on outcomes that are only known at query plan execution time, and we account
/// for this by splitting a path into multiple paths (one for each possible outcome). The common
/// example is abstract types, where we may end up taking a different edge depending on the runtime
/// type (e.g. during type explosion).
#[derive(Clone)]
pub(crate) struct SimultaneousPaths(pub(crate) Vec<Arc<OpGraphPath>>);

impl SimultaneousPaths {
    pub(crate) fn fmt_indented(&self, f: &mut IndentedFormatter) -> std::fmt::Result {
        match self.0.as_slice() {
            [] => f.write("<no path>"),

            [first] => f.write_fmt(format_args!("{{ {first} }}")),

            _ => {
                f.write("{")?;
                write_indented_lines(f, &self.0, |f, elem| f.write(elem))?;
                f.write("}")
            }
        }
    }
}

impl std::fmt::Debug for SimultaneousPaths {
    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
        f.debug_list()
            .entries(self.0.iter().map(ToString::to_string))
            .finish()
    }
}

impl std::fmt::Display for SimultaneousPaths {
    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
        self.fmt_indented(&mut IndentedFormatter::new(f))
    }
}

/// One of the options for an `OpenBranch` (see the documentation of that struct for details). This
/// includes the simultaneous paths we are traversing for the option, along with metadata about the
/// traversal.
// PORT_NOTE: The JS codebase stored a `ConditionResolver` callback here, but it was the same for
// a given traversal (and cached resolution across the traversal), so we accordingly store it in
// `QueryPlanTraversal` and pass it down when needed instead.
#[derive(Debug, Clone)]
pub(crate) struct SimultaneousPathsWithLazyIndirectPaths {
    pub(crate) paths: SimultaneousPaths,
    pub(crate) context: OpGraphPathContext,
    pub(crate) excluded_destinations: ExcludedDestinations,
    pub(crate) excluded_conditions: ExcludedConditions,
    pub(crate) lazily_computed_indirect_paths: Vec<Option<OpIndirectPaths>>,
}

/// A "set" of excluded destinations (i.e. subgraph names). Note that we use a `Vec` instead of set
/// because this is used in pretty hot paths (the whole path computation is CPU intensive) and will
/// basically always be tiny (it's bounded by the number of distinct key on a given type, so usually
/// 2-3 max; even in completely unrealistic cases, it's hard bounded by the number of subgraphs), so
/// a `Vec` is going to perform a lot better than `IndexSet` in practice.
#[derive(Debug, Clone)]
pub(crate) struct ExcludedDestinations(Arc<Vec<NodeStr>>);

impl ExcludedDestinations {
    fn is_excluded(&self, destination: &NodeStr) -> bool {
        self.0.contains(destination)
    }

    fn add_excluded(&self, destination: NodeStr) -> Self {
        if !self.is_excluded(&destination) {
            let mut new = self.0.as_ref().clone();
            new.push(destination);
            Self(Arc::new(new))
        } else {
            self.clone()
        }
    }
}

impl PartialEq for ExcludedDestinations {
    /// See if two `ExcludedDestinations` have the same set of values, regardless of their ordering.
    fn eq(&self, other: &ExcludedDestinations) -> bool {
        self.0.len() == other.0.len() && self.0.iter().all(|x| other.0.contains(x))
    }
}

impl Default for ExcludedDestinations {
    fn default() -> Self {
        ExcludedDestinations(Arc::new(vec![]))
    }
}

#[derive(Debug, Clone)]
pub(crate) struct ExcludedConditions(Arc<Vec<Arc<SelectionSet>>>);

impl ExcludedConditions {
    pub(crate) fn is_empty(&self) -> bool {
        self.0.is_empty()
    }

    fn is_excluded(&self, condition: Option<&Arc<SelectionSet>>) -> bool {
        let Some(condition) = condition else {
            return false;
        };
        self.0.contains(condition)
    }

    /// Immutable version of `push`.
    pub(crate) fn add_item(&self, value: &SelectionSet) -> ExcludedConditions {
        let mut result = self.0.as_ref().clone();
        result.push(value.clone().into());
        ExcludedConditions(Arc::new(result))
    }
}

impl Default for ExcludedConditions {
    fn default() -> Self {
        ExcludedConditions(Arc::new(vec![]))
    }
}

#[derive(Clone)]
pub(crate) struct IndirectPaths<TTrigger, TEdge>
where
    TTrigger: Eq + Hash,
    Arc<TTrigger>: Into<GraphPathTrigger>,
    TEdge: Copy + Into<Option<EdgeIndex>>,
    EdgeIndex: Into<TEdge>,
{
    paths: Arc<Vec<Arc<GraphPath<TTrigger, TEdge>>>>,
    dead_ends: Arc<Unadvanceables>,
}

type OpIndirectPaths = IndirectPaths<OpGraphPathTrigger, Option<EdgeIndex>>;

impl std::fmt::Debug for OpIndirectPaths {
    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("OpIndirectPaths")
            .field(
                "paths",
                &self
                    .paths
                    .iter()
                    .map(ToString::to_string)
                    .collect::<Vec<_>>(),
            )
            .field("dead_ends", &self.dead_ends)
            .finish()
    }
}

impl OpIndirectPaths {
    /// When `self` is just-computed indirect paths and given a field that we're trying to advance
    /// after those paths, this method filters any paths that should not be considered.
    ///
    /// Currently, this handles the case where the key used at the end of the indirect path contains
    /// (at top level) the field being queried. Or to make this more concrete, if we're trying to
    /// collect field `id`, and the path's last edge was using key `id`, then we can ignore that
    /// path because this implies that there is a way to fetch `id` "some other way".
    pub(crate) fn filter_non_collecting_paths_for_field(
        &self,
        field: &Field,
    ) -> Result<OpIndirectPaths, FederationError> {
        // We only handle leaves; Things are more complex for non-leaves.
        if !field.data().is_leaf()? {
            return Ok(self.clone());
        }

        let mut filtered = vec![];
        for path in self.paths.iter() {
            if let Some(Some(last_edge)) = path.edges.last() {
                let last_edge_weight = path.graph.edge_weight(*last_edge)?;
                if matches!(
                    last_edge_weight.transition,
                    QueryGraphEdgeTransition::KeyResolution
                ) {
                    if let Some(conditions) = &last_edge_weight.conditions {
                        if conditions.contains_top_level_field(field)? {
                            continue;
                        }
                    }
                }
            }
            filtered.push(path.clone())
        }
        Ok(if filtered.len() == self.paths.len() {
            self.clone()
        } else {
            OpIndirectPaths {
                paths: Arc::new(filtered),
                dead_ends: self.dead_ends.clone(),
            }
        })
    }
}

#[derive(Debug, Clone)]
struct Unadvanceables(Vec<Unadvanceable>);

impl Display for Unadvanceables {
    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
        f.write_char('[')?;
        let mut unadvanceables = self.0.iter();
        if let Some(unadvanceable) = unadvanceables.next() {
            unadvanceable.fmt(f)?;
            for unadvanceable in unadvanceables {
                f.write_str(", ")?;
                unadvanceable.fmt(f)?;
            }
        }
        f.write_char(']')
    }
}

#[derive(Debug, Clone)]
struct Unadvanceable {
    reason: UnadvanceableReason,
    from_subgraph: NodeStr,
    to_subgraph: NodeStr,
    details: String,
}

impl Display for Unadvanceable {
    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
        write!(
            f,
            "[{}]({}->{}) {}",
            self.reason, self.from_subgraph, self.to_subgraph, self.details
        )
    }
}

#[derive(Debug, Clone, strum_macros::Display)]
enum UnadvanceableReason {
    UnsatisfiableKeyCondition,
    UnsatisfiableRequiresCondition,
    UnresolvableInterfaceObject,
    NoMatchingTransition,
    UnreachableType,
    IgnoredIndirectPath,
}

/// One of the options for a `ClosedBranch` (see the documentation of that struct for details). Note
/// there is an optimization here, in that if some ending section of the path within the GraphQL
/// operation can be satisfied by a query to a single subgraph, then we just record that selection
/// set, and the `SimultaneousPaths` ends at the node at which that query is made instead of a node
/// for the leaf field. The selection set gets copied "as-is" into the `FetchNode`, and also avoids
/// extra `GraphPath` creation and work during `PathTree` merging.
#[derive(Debug)]
pub(crate) struct ClosedPath {
    pub(crate) paths: SimultaneousPaths,
    pub(crate) selection_set: Option<Arc<SelectionSet>>,
}

impl ClosedPath {
    pub(crate) fn flatten(
        &self,
    ) -> impl Iterator<Item = (&OpGraphPath, Option<&Arc<SelectionSet>>)> {
        self.paths
            .0
            .iter()
            .map(|path| (path.as_ref(), self.selection_set.as_ref()))
    }
}

impl std::fmt::Display for ClosedPath {
    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
        if let Some(ref selection_set) = self.selection_set {
            write!(f, "{} -> {}", self.paths, selection_set)
        } else {
            write!(f, "{}", self.paths)
        }
    }
}

/// A list of the options generated during query planning for a specific "closed branch", which is a
/// full/closed path in a GraphQL operation (i.e. one that ends in a leaf field).
#[derive(Debug)]
pub(crate) struct ClosedBranch(pub(crate) Vec<Arc<ClosedPath>>);

/// A list of the options generated during query planning for a specific "open branch", which is a
/// partial/open path in a GraphQL operation (i.e. one that does not end in a leaf field).
#[derive(Debug)]
pub(crate) struct OpenBranch(pub(crate) Vec<SimultaneousPathsWithLazyIndirectPaths>);

impl<TTrigger, TEdge> GraphPath<TTrigger, TEdge>
where
    TTrigger: Eq + Hash,
    Arc<TTrigger>: Into<GraphPathTrigger>,
    TEdge: Copy + Into<Option<EdgeIndex>>,
    EdgeIndex: Into<TEdge>,
{
    pub(crate) fn new(graph: Arc<QueryGraph>, head: NodeIndex) -> Result<Self, FederationError> {
        let mut path = Self {
            graph,
            head,
            tail: head,
            edges: vec![],
            edge_triggers: vec![],
            edge_conditions: vec![],
            last_subgraph_entering_edge_info: None,
            own_path_ids: Arc::new(IndexSet::new()),
            overriding_path_ids: Arc::new(IndexSet::new()),
            runtime_types_of_tail: Arc::new(IndexSet::new()),
            runtime_types_before_tail_if_last_is_cast: None,
            defer_on_tail: None,
        };
        path.runtime_types_of_tail = Arc::new(path.head_possible_runtime_types()?);
        Ok(path)
    }

    fn head_possible_runtime_types(
        &self,
    ) -> Result<IndexSet<ObjectTypeDefinitionPosition>, FederationError> {
        let head_weight = self.graph.node_weight(self.head)?;
        Ok(match &head_weight.type_ {
            QueryGraphNodeType::SchemaType(head_type_pos) => {
                let head_type_pos: CompositeTypeDefinitionPosition =
                    head_type_pos.clone().try_into()?;
                self.graph
                    .schema_by_source(&head_weight.source)?
                    .possible_runtime_types(head_type_pos)?
            }
            QueryGraphNodeType::FederatedRootType(_) => IndexSet::new(),
        })
    }

    pub(crate) fn add(
        &self,
        trigger: TTrigger,
        edge: TEdge,
        condition_resolution: ConditionResolution,
        defer: Option<DeferDirectiveArguments>,
    ) -> Result<Self, FederationError> {
        let ConditionResolution::Satisfied {
            path_tree: condition_path_tree,
            cost: condition_cost,
        } = condition_resolution
        else {
            return Err(FederationError::internal(
                "Cannot add an edge to a path if its conditions cannot be satisfied",
            ));
        };

        let mut edges = self.edges.clone();
        let mut edge_triggers = self.edge_triggers.clone();
        let mut edge_conditions = self.edge_conditions.clone();

        let Some(new_edge) = edge.into() else {
            edges.push(edge);
            edge_triggers.push(Arc::new(trigger));
            edge_conditions.push(condition_path_tree);
            return Ok(GraphPath {
                graph: self.graph.clone(),
                head: self.head,
                tail: self.tail,
                edges,
                edge_triggers,
                edge_conditions,
                // We clear `last_subgraph_entering_edge_info` as we enter a `@defer`. That is
                // because `last_subgraph_entering_edge_info` is used to eliminate some non-optimal
                // paths, but we don't want those optimizations to bypass a `@defer` application.
                last_subgraph_entering_edge_info: if defer.is_some() {
                    None
                } else {
                    self.last_subgraph_entering_edge_info.clone()
                },
                own_path_ids: self.own_path_ids.clone(),
                overriding_path_ids: self.overriding_path_ids.clone(),
                runtime_types_of_tail: Arc::new(
                    self.graph
                        .advance_possible_runtime_types(&self.runtime_types_of_tail, None)?,
                ),
                runtime_types_before_tail_if_last_is_cast: None,
                defer_on_tail: defer,
            });
        };

        let (edge_head, edge_tail) = self.graph.edge_endpoints(new_edge)?;
        let edge_weight = self.graph.edge_weight(new_edge)?;
        let tail_weight = self.graph.node_weight(self.tail)?;
        if self.tail != edge_head {
            return Err(FederationError::internal(format!(
                "Cannot add edge {} to path ending at {}",
                edge_weight, tail_weight
            )));
        }
        if let Some(path_tree) = &condition_path_tree {
            if edge_weight.conditions.is_none() {
                return Err(FederationError::internal(format!(
                    "Unexpectedly got conditions paths {} for edge {} without conditions",
                    path_tree, edge_weight,
                )));
            }
        }

        if matches!(
            edge_weight.transition,
            QueryGraphEdgeTransition::Downcast { .. }
        ) {
            if let Some(Some(last_edge)) = self.edges.last().map(|e| (*e).into()) {
                let Some(last_edge_trigger) = self.edge_triggers.last() else {
                    return Err(FederationError::internal(
                        "Could not find corresponding trigger for edge",
                    ));
                };
                if let GraphPathTrigger::Op(last_operation_element) =
                    last_edge_trigger.clone().into()
                {
                    if let OpGraphPathTrigger::OpPathElement(OpPathElement::InlineFragment(
                        last_operation_element,
                    )) = last_operation_element.as_ref()
                    {
                        if last_operation_element.data().directives.is_empty() {
                            // This mean we have 2 typecasts back-to-back, and that means the
                            // previous operation element might not be useful on this path. More
                            // precisely, the previous typecast was only useful if it restricted the
                            // possible runtime types of the type on which it applied more than the
                            // current typecast does (but note that if the previous typecast had
                            // directives, we keep it no matter what in case those directives are
                            // important).
                            //
                            // That is, we're in the case where we have (somewhere potentially deep
                            // in a query):
                            //   f {  # field 'f' of type A
                            //     ... on B {
                            //       ... on C {
                            //          # more stuff
                            //       }
                            //     }
                            //   }
                            // If the intersection of A and C is non empty and included (or equal)
                            // to the intersection of A and B, then there is no reason to have
                            // `... on B` at all because:
                            //  1. you can do `... on C` on `f` directly since the intersection of A
                            //     and C is non-empty.
                            //  2. `... on C` restricts strictly more than `... on B` and so the
                            //     latter can't impact the result.
                            // So if we detect that we're in that situation, we remove the
                            // `... on B` (but note that this is an optimization, keeping `... on B`
                            // wouldn't be incorrect, just useless).
                            let Some(runtime_types_before_tail) =
                                &self.runtime_types_before_tail_if_last_is_cast
                            else {
                                return Err(FederationError::internal(
                                    "Could not find runtime types of path prior to inline fragment",
                                ));
                            };
                            let new_runtime_types_of_tail =
                                self.graph.advance_possible_runtime_types(
                                    runtime_types_before_tail,
                                    Some(new_edge),
                                )?;
                            if !new_runtime_types_of_tail.is_empty()
                                && new_runtime_types_of_tail.is_subset(&self.runtime_types_of_tail)
                            {
                                // Note that `edge` starts at the node we wish to eliminate from the
                                // path. So we need to replace it with the edge going directly from
                                // the previous node to the new tail for this path.
                                //
                                // PORT_NOTE: The JS codebase has a bug where it doesn't check that
                                // the searched edges are downcast edges. We fix that here.
                                let (last_edge_head, _) = self.graph.edge_endpoints(last_edge)?;
                                let edge_tail_weight = self.graph.node_weight(edge_tail)?;
                                let mut new_edge = None;
                                for new_edge_ref in self.graph.out_edges(last_edge_head) {
                                    if !matches!(
                                        new_edge_ref.weight().transition,
                                        QueryGraphEdgeTransition::Downcast { .. }
                                    ) {
                                        continue;
                                    }
                                    if self.graph.node_weight(new_edge_ref.target())?.type_
                                        == edge_tail_weight.type_
                                    {
                                        new_edge = Some(new_edge_ref.id());
                                        break;
                                    }
                                }
                                if let Some(new_edge) = new_edge {
                                    // We replace the previous operation element with this one.
                                    edges.pop();
                                    edge_triggers.pop();
                                    edge_conditions.pop();
                                    edges.push(new_edge.into());
                                    edge_triggers.push(Arc::new(trigger));
                                    edge_conditions.push(condition_path_tree);
                                    return Ok(GraphPath {
                                        graph: self.graph.clone(),
                                        head: self.head,
                                        tail: edge_tail,
                                        edges,
                                        edge_triggers,
                                        edge_conditions,
                                        last_subgraph_entering_edge_info: self
                                            .last_subgraph_entering_edge_info
                                            .clone(),
                                        own_path_ids: self.own_path_ids.clone(),
                                        overriding_path_ids: self.overriding_path_ids.clone(),
                                        runtime_types_of_tail: Arc::new(new_runtime_types_of_tail),
                                        runtime_types_before_tail_if_last_is_cast: self
                                            .runtime_types_before_tail_if_last_is_cast
                                            .clone(),
                                        // We know the edge is a `DownCast`, so if there is no new
                                        // `@defer` taking precedence, we just inherit the prior
                                        // version.
                                        defer_on_tail: if defer.is_some() {
                                            defer
                                        } else {
                                            self.defer_on_tail.clone()
                                        },
                                    });
                                }
                            }
                        }
                    }
                }
            }
        }

        if matches!(
            edge_weight.transition,
            QueryGraphEdgeTransition::KeyResolution { .. }
        ) {
            // We're adding a `@key` edge. If the last edge to that point is an `@interfaceObject`
            // fake downcast, and if our destination type is not an `@interfaceObject` itself, then
            // we can eliminate that last edge as it does nothing useful (also, it has conditions
            // and we don't need/want the `@key` we're following to depend on those conditions,
            // since it doesn't have to).
            let edge_tail_weight = self.graph.node_weight(edge_tail)?;
            if self.last_edge_is_interface_object_fake_down_cast()?
                && matches!(
                    edge_tail_weight.type_,
                    QueryGraphNodeType::SchemaType(OutputTypeDefinitionPosition::Interface(_))
                )
            {
                // We replace the previous operation element with this one.
                edges.pop();
                edge_triggers.pop();
                edge_conditions.pop();
                edges.push(edge);
                edge_triggers.push(Arc::new(trigger));
                edge_conditions.push(condition_path_tree);
                return Ok(GraphPath {
                    graph: self.graph.clone(),
                    head: self.head,
                    tail: edge_tail,
                    edges,
                    edge_triggers,
                    edge_conditions,
                    // Again, we don't want to set `last_subgraph_entering_edge_info` if we're
                    // entering a `@defer` (see above).
                    //
                    // PORT_NOTE: In the JS codebase, the information for the last subgraph-entering
                    // is set incorrectly, in that the index is off by one. We fix that bug here.
                    last_subgraph_entering_edge_info: if defer.is_none()
                        && self.graph.is_cross_subgraph_edge(new_edge)?
                    {
                        Some(SubgraphEnteringEdgeInfo {
                            index: self.edges.len() - 1,
                            conditions_cost: condition_cost,
                        })
                    } else {
                        None
                    },
                    own_path_ids: self.own_path_ids.clone(),
                    overriding_path_ids: self.overriding_path_ids.clone(),
                    runtime_types_of_tail: Arc::new(self.graph.advance_possible_runtime_types(
                        &self.runtime_types_of_tail,
                        Some(new_edge),
                    )?),
                    // We know last edge is not a cast.
                    runtime_types_before_tail_if_last_is_cast: None,
                    defer_on_tail: defer,
                });
            }
        }

        edges.push(edge);
        edge_triggers.push(Arc::new(trigger));
        edge_conditions.push(condition_path_tree);
        Ok(GraphPath {
            graph: self.graph.clone(),
            head: self.head,
            tail: edge_tail,
            edges,
            edge_triggers,
            edge_conditions,
            // Again, we don't want to set `last_subgraph_entering_edge_info` if we're entering a
            // `@defer` (see above).
            last_subgraph_entering_edge_info: if defer.is_none()
                && self.graph.is_cross_subgraph_edge(new_edge)?
            {
                Some(SubgraphEnteringEdgeInfo {
                    index: self.edges.len(),
                    conditions_cost: condition_cost,
                })
            } else {
                None
            },
            own_path_ids: self.own_path_ids.clone(),
            overriding_path_ids: self.overriding_path_ids.clone(),
            runtime_types_of_tail: Arc::new(
                self.graph
                    .advance_possible_runtime_types(&self.runtime_types_of_tail, Some(new_edge))?,
            ),
            runtime_types_before_tail_if_last_is_cast: if matches!(
                edge_weight.transition,
                QueryGraphEdgeTransition::Downcast { .. }
            ) {
                Some(self.runtime_types_of_tail.clone())
            } else {
                None
            },
            // If there is no new `@defer` taking precedence, and the edge is downcast, then we
            // inherit the prior version. This is because we only try to re-enter subgraphs for
            // `@defer` on concrete fields, so as long as we add downcasts, we should remember that
            // we still need to try re-entering the subgraph.
            defer_on_tail: if defer.is_some() {
                defer
            } else if matches!(
                edge_weight.transition,
                QueryGraphEdgeTransition::Downcast { .. }
            ) {
                self.defer_on_tail.clone()
            } else {
                None
            },
        })
    }

    pub(crate) fn iter(&self) -> impl Iterator<Item = GraphPathItem<'_, TTrigger, TEdge>> {
        debug_assert_eq!(self.edges.len(), self.edge_triggers.len());
        debug_assert_eq!(self.edges.len(), self.edge_conditions.len());
        self.edges
            .iter()
            .copied()
            .zip(&self.edge_triggers)
            .zip(&self.edge_conditions)
            .map(|((edge, trigger), condition)| (edge, trigger, condition))
    }

    pub(crate) fn next_edges<'a>(
        &'a self,
    ) -> Result<Box<dyn Iterator<Item = EdgeIndex> + 'a>, FederationError> {
        if self.defer_on_tail.is_some() {
            // If the path enters a `@defer` (meaning that what comes after needs to be deferred),
            // then it's the one special case where we explicitly need to ask for edges to self,
            // as we will force the use of a `@key` edge (so we can send the non-deferred part
            // immediately) and we may have to resume the deferred part in the same subgraph than
            // the one in which we were (hence the need for edges to self).
            return Ok(Box::new(
                self.graph
                    .out_edges_with_federation_self_edges(self.tail)
                    .into_iter()
                    .map(|edge_ref| edge_ref.id()),
            ));
        }

        // In theory, we could always return `self.graph.out_edges(self.tail)` here. But in
        // practice, `non_trivial_followup_edges` may give us a subset of those "out edges" that
        // avoids some of the edges that we know we don't need to check because they are guaranteed
        // to be inefficient after the last edge. Note that is purely an optimization (see
        // https://github.com/apollographql/federation/pull/1653 for more details).
        if let Some(last_edge) = self.edges.last() {
            if let Some(last_edge) = (*last_edge).into() {
                let Some(non_trivial_followup_edges) =
                    self.graph.non_trivial_followup_edges.get(&last_edge)
                else {
                    return Err(FederationError::internal(
                        "Unexpectedly missing entry for non-trivial followup edges map",
                    ));
                };
                return Ok(Box::new(non_trivial_followup_edges.iter().copied()));
            }
        }

        Ok(Box::new(
            self.graph
                .out_edges(self.tail)
                .into_iter()
                .map(|edge_ref| edge_ref.id()),
        ))
    }

    fn is_on_top_level_query_root(&self) -> Result<bool, FederationError> {
        let head_weight = self.graph.node_weight(self.head)?;
        if !matches!(head_weight.type_, QueryGraphNodeType::FederatedRootType(_)) {
            return Ok(false);
        }

        // We walk the path's edges and as soon as we take a field (or the node is not a federated
        // root or a subgraph root), we know we're not on the top-level query/mutation/subscription
        // root anymore. The reason we don't just check that size <= 1 is that we could have a
        // top-level `... on Query` inline fragment that doesn't actually change the type.
        for edge in &self.edges {
            let Some(edge) = (*edge).into() else {
                continue;
            };

            let edge_weight = self.graph.edge_weight(edge)?;
            if matches!(
                edge_weight.transition,
                QueryGraphEdgeTransition::FieldCollection { .. }
            ) {
                return Ok(false);
            }

            let (_, tail) = self.graph.edge_endpoints(edge)?;
            let tail_weight = self.graph.node_weight(tail)?;
            let QueryGraphNodeType::SchemaType(tail_type_pos) = &tail_weight.type_ else {
                return Err(FederationError::internal(
                    "Edge tail is unexpectedly a federated root",
                ));
            };

            let tail_schema = self.graph.schema_by_source(&tail_weight.source)?;
            let tail_schema_definition = &tail_schema.schema().schema_definition;
            if let Some(query_type_name) = &tail_schema_definition.query {
                if tail_type_pos.type_name() == &query_type_name.name {
                    continue;
                }
            }
            if let Some(mutation_type_name) = &tail_schema_definition.mutation {
                if tail_type_pos.type_name() == &mutation_type_name.name {
                    continue;
                }
            }
            if let Some(subscription_type_name) = &tail_schema_definition.subscription {
                if tail_type_pos.type_name() == &subscription_type_name.name {
                    continue;
                }
            }
            return Ok(false);
        }
        Ok(true)
    }

    fn tail_is_interface_object(&self) -> Result<bool, FederationError> {
        let tail_weight = self.graph.node_weight(self.tail)?;

        let QueryGraphNodeType::SchemaType(OutputTypeDefinitionPosition::Object(
            tail_type_position,
        )) = &tail_weight.type_
        else {
            return Ok(false);
        };

        let subgraph_schema = self.graph.schema_by_source(&tail_weight.source)?;
        let federation_spec_definition =
            get_federation_spec_definition_from_subgraph(subgraph_schema)?;
        let Some(interface_object_directive_definition) =
            federation_spec_definition.interface_object_directive_definition(subgraph_schema)?
        else {
            return Ok(false);
        };
        let tail_type = tail_type_position.get(subgraph_schema.schema())?;
        Ok(tail_type
            .directives
            .iter()
            .any(|directive| directive.name == interface_object_directive_definition.name))
    }

    fn last_edge_is_interface_object_fake_down_cast(&self) -> Result<bool, FederationError> {
        let Some(last_edge) = self.edges.last() else {
            return Ok(false);
        };
        let Some(last_edge) = (*last_edge).into() else {
            return Ok(false);
        };
        let last_edge_weight = self.graph.edge_weight(last_edge)?;
        Ok(matches!(
            last_edge_weight.transition,
            QueryGraphEdgeTransition::InterfaceObjectFakeDownCast { .. }
        ))
    }

    // PORT_NOTE: In the JS codebase, this was named
    // `lastIsIntefaceObjectFakeDownCastAfterEnteringSubgraph`.
    fn last_edge_is_interface_object_fake_down_cast_after_entering_subgraph(
        &self,
    ) -> Result<bool, FederationError> {
        Ok(self.last_edge_is_interface_object_fake_down_cast()?
            && self
            .last_subgraph_entering_edge_info
            .as_ref()
            .map(|edge_info| edge_info.index)
            // `len - 1` is the last index (the fake down cast), so `len - 2` is the previous edge.
            == Some(self.edges.len() - 2))
    }

    fn can_satisfy_conditions(
        &self,
        edge: EdgeIndex,
        condition_resolver: &mut impl ConditionResolver,
        context: &OpGraphPathContext,
        excluded_destinations: &ExcludedDestinations,
        excluded_conditions: &ExcludedConditions,
    ) -> Result<ConditionResolution, FederationError> {
        let edge_weight = self.graph.edge_weight(edge)?;
        if edge_weight.conditions.is_none() {
            return Ok(ConditionResolution::no_conditions());
        }
        let resolution = condition_resolver.resolve(
            edge,
            context,
            excluded_destinations,
            excluded_conditions,
        )?;
        if let Some(Some(last_edge)) = self.edges.last().map(|e| (*e).into()) {
            if matches!(
                edge_weight.transition,
                QueryGraphEdgeTransition::FieldCollection { .. }
            ) {
                let last_edge_weight = self.graph.edge_weight(last_edge)?;
                if !matches!(
                    last_edge_weight.transition,
                    QueryGraphEdgeTransition::KeyResolution
                ) {
                    let in_same_subgraph = if let ConditionResolution::Satisfied {
                        path_tree: Some(path_tree),
                        ..
                    } = &resolution
                    {
                        path_tree.is_all_in_same_subgraph()?
                    } else {
                        true
                    };
                    if in_same_subgraph {
                        let (edge_head, _) = self.graph.edge_endpoints(edge)?;
                        if self.graph.get_locally_satisfiable_key(edge_head)?.is_none() {
                            return Ok(ConditionResolution::Unsatisfied {
                                reason: Some(UnsatisfiedConditionReason::NoPostRequireKey),
                            });
                        };
                        // We're in a case where we have an `@requires` application (we have
                        // conditions and the new edge has a `FieldCollection` transition) and we
                        // have to jump to another subgraph to satisfy the `@requires`, which means
                        // we need to use a key on "the current subgraph" to resume collecting the
                        // field with the `@requires`. `get_locally_satisfiable_key()` essentially
                        // tells us that we have such key, and that's good enough here. Note that
                        // the way the code is organised, we don't use an actual edge of the query
                        // graph, so we cannot use `condition_resolver` and so it's not easy to get
                        // a proper cost or tree. That's ok in the sense that the cost of the key is
                        // negligible because we know it's a "local" one (there is no subgraph jump)
                        // and the code to build plan will deal with adding that key anyway (so not
                        // having the tree is ok).
                        // TODO(Sylvain): the whole handling of `@requires` is a bit too complex and
                        // hopefully we might be able to clean that up, but it's unclear to me how
                        // at the moment and it may not be a small change so this will have to do
                        // for now.
                    }
                }
            }
        }
        Ok(resolution)
    }

    // TODO: We've skipped populating `Unadvanceables` information because it's only needed during
    // composition, but we'll need to port that code when we port composition.
    // PORT_NOTE: In the JS codebase, this was named
    // `advancePathWithNonCollectingAndTypePreservingTransitions`.
    fn advance_with_non_collecting_and_type_preserving_transitions(
        self: &Arc<Self>,
        context: &OpGraphPathContext,
        condition_resolver: &mut impl ConditionResolver,
        excluded_destinations: &ExcludedDestinations,
        excluded_conditions: &ExcludedConditions,
        transition_and_context_to_trigger: impl Fn(
            &QueryGraphEdgeTransition,
            &OpGraphPathContext,
        ) -> TTrigger,
        node_and_trigger_to_edge: impl Fn(&Arc<QueryGraph>, NodeIndex, &Arc<TTrigger>) -> Option<TEdge>,
    ) -> Result<IndirectPaths<TTrigger, TEdge>, FederationError> {
        // If we're asked for indirect paths after an "@interfaceObject fake down cast" but that
        // down cast comes just after non-collecting edge(s), then we can ignore the ask (skip
        // indirect paths from there). The reason is that the presence of the non-collecting edges
        // just before the fake down cast means we looked at indirect paths just before that
        // down cast, but that fake down cast really does nothing in practice with the subgraph it's
        // on, so any indirect path from that fake down cast will have a valid indirect path
        // before it, and so will have been taken into account independently.
        if self.last_edge_is_interface_object_fake_down_cast_after_entering_subgraph()? {
            return Ok(IndirectPaths {
                paths: Arc::new(vec![]),
                dead_ends: Arc::new(Unadvanceables(vec![])),
            });
        }

        let is_top_level_path = self.is_on_top_level_query_root()?;
        let tail_weight = self.graph.node_weight(self.tail)?;
        let tail_type_pos = if let QueryGraphNodeType::SchemaType(type_) = &tail_weight.type_ {
            Some(type_)
        } else {
            None
        };
        let original_source = tail_weight.source.clone();
        // For each source, we store the best path we find for that source with the score, or `None`
        // if we can decide that we should not try going to that source (typically because we can
        // prove that this create an inefficient detour for which a more direct path exists and will
        // be found).
        type BestPathInfo<TTrigger, TEdge> =
            Option<(Arc<GraphPath<TTrigger, TEdge>>, QueryPlanCost)>;
        let mut best_path_by_source: IndexMap<NodeStr, BestPathInfo<TTrigger, TEdge>> =
            IndexMap::new();
        let dead_ends = vec![];
        // Note that through `excluded` we avoid taking the same edge from multiple options. But
        // that means it's important we try the smallest paths first. That is, if we could in theory
        // have path A -> B and A -> C -> B, and we can do B -> D, then we want to keep A -> B -> D,
        // not A -> C -> B -> D.
        let mut heap: BinaryHeap<HeapElement<TTrigger, TEdge>> = BinaryHeap::new();
        heap.push(HeapElement(self.clone()));
        while let Some(HeapElement(to_advance)) = heap.pop() {
            for edge in to_advance.next_edges()? {
                let edge_weight = self.graph.edge_weight(edge)?;
                if edge_weight.transition.collect_operation_elements() {
                    continue;
                }
                let (edge_head, edge_tail) = self.graph.edge_endpoints(edge)?;
                let edge_tail_weight = self.graph.node_weight(edge_tail)?;

                if excluded_destinations.is_excluded(&edge_tail_weight.source) {
                    continue;
                }

                // If the edge takes us back to the subgraph in which we started, we're not really
                // interested (we've already checked for a direct transition from that original
                // subgraph). One exception though is if we're just after a @defer, in which case
                // re-entering the current subgraph is actually useful.
                if edge_tail_weight.source == original_source && to_advance.defer_on_tail.is_none()
                {
                    continue;
                }

                // We have edges between Query objects so that if a field returns a query object, we
                // can jump to any subgraph at that point. However, there is no point of using those
                // edges at the beginning of a path, except for when we have a @defer, in which case
                // we want to allow re-entering the same subgraph.
                if is_top_level_path
                    && matches!(
                        edge_weight.transition,
                        QueryGraphEdgeTransition::RootTypeResolution { .. }
                    )
                    && !(to_advance.defer_on_tail.is_some()
                        && self.graph.is_self_key_or_root_edge(edge)?)
                {
                    continue;
                }

                let prev_for_source = best_path_by_source.get(&edge_tail_weight.source);
                let prev_for_source = match prev_for_source {
                    Some(Some(prev_for_source)) => Some(prev_for_source),
                    Some(None) => continue,
                    None => None,
                };

                if let Some(prev_for_source) = prev_for_source {
                    if (prev_for_source.0.edges.len() < to_advance.edges.len() + 1)
                        || (prev_for_source.0.edges.len() == to_advance.edges.len() + 1
                            && prev_for_source.1 <= 1)
                    {
                        // We've already found another path that gets us to the same subgraph rather
                        // than the edge we're about to check. If that previous path is strictly
                        // shorter than the path we'd obtain with the new edge, then we don't
                        // consider this edge (it's a longer way to get to the same place). And if
                        // the previous path is the same size (as the one obtained with that edge),
                        // but that previous path's cost for getting the condition was 0 or 1, then
                        // the new edge cannot really improve on this and we don't bother with it.
                        //
                        // Note that a cost of 0 can only happen during composition validation where
                        // all costs are 0 to mean "we don't care about costs". This effectively
                        // means that for validation, as soon as we have a path to a subgraph, we
                        // ignore other options even if they may be "faster".
                        continue;
                    }
                }

                if excluded_conditions.is_excluded(edge_weight.conditions.as_ref()) {
                    continue;
                }

                // As we validate the condition for this edge, it might be necessary to jump to
                // another subgraph, but if for that we need to jump to the same subgraph we're
                // trying to get to, then it means there is another, shorter way to go to our
                // destination and we can return that shorter path, not the one with the edge
                // we're trying.
                let condition_resolution = to_advance.can_satisfy_conditions(
                    edge,
                    condition_resolver,
                    context,
                    &excluded_destinations.add_excluded(edge_tail_weight.source.clone()),
                    excluded_conditions,
                )?;
                if let ConditionResolution::Satisfied { path_tree, cost } = condition_resolution {
                    // We can get to `edge_tail_weight.source` with that edge. But if we had already
                    // found another path to the same subgraph, we want to replace it with this one
                    // only if either 1) it is shorter or 2) if it's of equal size, only if the
                    // condition cost is lower than the previous one.
                    if let Some(prev_for_source) = prev_for_source {
                        if prev_for_source.0.edges.len() == to_advance.edges.len() + 1
                            && prev_for_source.1 <= cost
                        {
                            continue;
                        }
                    }

                    // It's important we minimize the number of options this method returns, because
                    // during query planning with many fields, options here translate to state
                    // explosion. This is why above we eliminated edges that provably have better
                    // options.
                    //
                    // But we can do a slightly more involved check. Suppose we have a few subgraphs
                    // A, B and C, and suppose that we're considering an edge from B to C. We can
                    // then look at which subgraph we were in before reaching B (which can be "none"
                    // if the query starts at B), and let say that it is A. In other words, if we
                    // use the edge we're considering, we'll be looking at a path like:
                    //   ... -> A -> B -> <some fields in B> -> C
                    //
                    // Now, we can fairly easily check if the fields we collected in B (the `<some
                    // fields in B>`) can be also collected directly (without keys, nor requires)
                    // from A and if after that we could take an edge to C. If we can do all that,
                    // then we know that the path we're considering is strictly less efficient than:
                    //   ... -> A -> <same fields but in A> -> C
                    //
                    // Furthermore, since we've confirmed its a valid path, it will be found by
                    // another branch of the algorithm. In that case, we can ignore the edge to C,
                    // knowing a better path exists. Doing this drastically reduces state explosion
                    // in a number of cases.
                    if let Some(last_subgraph_entering_edge_info) =
                        &to_advance.last_subgraph_entering_edge_info
                    {
                        let Some(last_subgraph_entering_edge) =
                            to_advance.edges[last_subgraph_entering_edge_info.index].into()
                        else {
                            return Err(FederationError::internal(
                                "Subgraph-entering edge is unexpectedly absent",
                            ));
                        };

                        let (last_subgraph_entering_edge_head, last_subgraph_entering_edge_tail) =
                            self.graph.edge_endpoints(last_subgraph_entering_edge)?;
                        let last_subgraph_entering_edge_tail_weight =
                            self.graph.node_weight(last_subgraph_entering_edge_tail)?;
                        let QueryGraphNodeType::SchemaType(
                            last_subgraph_entering_edge_tail_type_pos,
                        ) = &last_subgraph_entering_edge_tail_weight.type_
                        else {
                            return Err(FederationError::internal(
                                "Subgraph-entering edge tail is unexpectedly a federated root",
                            ));
                        };
                        if Some(last_subgraph_entering_edge_tail_type_pos) != tail_type_pos {
                            let last_subgraph_entering_edge_weight =
                                self.graph.edge_weight(last_subgraph_entering_edge)?;

                            // If the previous subgraph is an actual subgraph, the head of the last
                            // subgraph-entering edge would be where a direct path starts. If the
                            // previous subgraph is a federated root, we instead take the previous
                            // subgraph to be the destination subgraph of this edge, and that
                            // subgraph's root of the same root kind (if it exists) would be where a
                            // direct path starts.
                            let direct_path_start_node = if matches!(
                                last_subgraph_entering_edge_weight.transition,
                                QueryGraphEdgeTransition::SubgraphEnteringTransition
                            ) {
                                let root = to_advance.head;
                                let root_weight = self.graph.node_weight(root)?;
                                let QueryGraphNodeType::FederatedRootType(root_kind) =
                                    &root_weight.type_
                                else {
                                    return Err(FederationError::internal("Encountered non-root path with a subgraph-entering transition"));
                                };
                                self.graph
                                    .root_kinds_to_nodes_by_source(&edge_tail_weight.source)?
                                    .get(root_kind)
                                    .copied()
                            } else {
                                Some(last_subgraph_entering_edge_head)
                            };

                            // If the previous subgraph is a federated root, as noted above we take
                            // the previous subgraph to instead be the destination subgraph of this
                            // edge, so we must manually indicate that here.
                            let is_edge_to_previous_subgraph = if matches!(
                                last_subgraph_entering_edge_weight.transition,
                                QueryGraphEdgeTransition::SubgraphEnteringTransition
                            ) {
                                true
                            } else {
                                let last_subgraph_entering_edge_head_weight =
                                    self.graph.node_weight(last_subgraph_entering_edge_head)?;
                                last_subgraph_entering_edge_head_weight.source
                                    == last_subgraph_entering_edge_tail_weight.source
                            };

                            let direct_path_end_node =
                                if let Some(direct_path_start_node) = direct_path_start_node {
                                    let QueryGraphNodeType::SchemaType(edge_tail_type_pos) =
                                        &edge_tail_weight.type_
                                    else {
                                        return Err(FederationError::internal(
                                            "Edge tail is unexpectedly a federated root",
                                        ));
                                    };
                                    self.check_direct_path_from_node(
                                        last_subgraph_entering_edge_info.index + 1,
                                        direct_path_start_node,
                                        edge_tail_type_pos,
                                        &node_and_trigger_to_edge,
                                    )?
                                } else {
                                    None
                                };

                            if let Some(direct_path_end_node) = direct_path_end_node {
                                let direct_key_edge_max_cost = last_subgraph_entering_edge_info
                                    .conditions_cost
                                    + if is_edge_to_previous_subgraph {
                                        0
                                    } else {
                                        cost
                                    };
                                if is_edge_to_previous_subgraph
                                    || self.graph.has_satisfiable_direct_key_edge(
                                        direct_path_end_node,
                                        &edge_tail_weight.source,
                                        condition_resolver,
                                        direct_key_edge_max_cost,
                                    )?
                                {
                                    // We just found that going to the previous subgraph is useless
                                    // because there is a more direct path. But we additionally
                                    // record that this previous subgraph should be avoided
                                    // altogether because some other longer path could try to get
                                    // back to that same source but defeat this specific check due
                                    // to having taken another edge first (and thus the last
                                    // subgraph-entering edge is different).
                                    //
                                    // What we mean here is that if `to_advance` path is
                                    //   ... -> A -> B -> <some fields in B>
                                    // and we just found that we don't want to keep
                                    //   ... -> A -> B -> <some fields in B> -> A
                                    // because we know
                                    //   ... -> A -> <some fields in A>
                                    // is possible directly, then we don't want this
                                    // method to later add
                                    //   ... -> A -> B -> <some fields in B> -> C -> A
                                    // as that is equally not useful.
                                    best_path_by_source
                                        .insert(edge_tail_weight.source.clone(), None);
                                    continue;
                                }
                            }
                        }
                    }

                    let updated_path = Arc::new(to_advance.add(
                        transition_and_context_to_trigger(&edge_weight.transition, context),
                        edge.into(),
                        ConditionResolution::Satisfied { cost, path_tree },
                        None,
                    )?);
                    best_path_by_source.insert(
                        edge_tail_weight.source.clone(),
                        Some((updated_path.clone(), cost)),
                    );
                    // It can be necessary to "chain" keys, because different subgraphs may have
                    // different keys exposed, and so we when we took a key, we want to check if
                    // there is a new key we can now use that takes us to other subgraphs. For other
                    // non-collecting edges ('RootTypeResolution' and 'SubgraphEnteringTransition')
                    // however, chaining never give us additional value.
                    //
                    // One exception is the case of self-edges (which stay on the same node), as
                    // those will only be looked at just after a @defer to handle potentially
                    // re-entering the same subgraph. When we take this, there's no point in looking
                    // for chaining since we'll independently check the other edges already.
                    if matches!(
                        edge_weight.transition,
                        QueryGraphEdgeTransition::KeyResolution
                    ) {
                        let edge_head_weight = self.graph.node_weight(edge_head)?;
                        if edge_head_weight.source != edge_tail_weight.source {
                            heap.push(HeapElement(updated_path));
                        }
                    }
                }
            }
        }

        Ok(IndirectPaths {
            paths: Arc::new(
                best_path_by_source
                    .into_values()
                    .flatten()
                    .map(|p| p.0)
                    .collect(),
            ),
            dead_ends: Arc::new(Unadvanceables(dead_ends)),
        })
    }

    /// Checks whether the partial path starting at the given edge index has an alternative path
    /// starting from the given node, where only direct edges are considered, and returns the node
    /// such a path ends on if it exists. Additionally, this method checks that the ending node has
    /// the given type.
    // PORT_NOTE: In the JS codebase, this was named `checkDirectPathFromPreviousSubgraphTo`. We've
    // also generalized this method a bit by shifting certain logic into the caller.
    fn check_direct_path_from_node(
        &self,
        start_index: usize,
        start_node: NodeIndex,
        end_type_position: &OutputTypeDefinitionPosition,
        node_and_trigger_to_edge: impl Fn(&Arc<QueryGraph>, NodeIndex, &Arc<TTrigger>) -> Option<TEdge>,
    ) -> Result<Option<NodeIndex>, FederationError> {
        let mut current_node = start_node;
        for index in start_index..self.edges.len() {
            let trigger = &self.edge_triggers[index];
            let Some(edge) = node_and_trigger_to_edge(&self.graph, current_node, trigger) else {
                return Ok(None);
            };

            // If the edge is `None`, this means the trigger doesn't require taking an edge (it's
            // typically an inline fragment with no type condition, just directives), which we can
            // always match.
            let Some(edge) = edge.into() else {
                continue;
            };

            // If the edge has conditions, we don't consider it a direct path as we don't know if
            // that condition can be satisfied and at what cost.
            let edge_weight = self.graph.edge_weight(edge)?;
            if edge_weight.conditions.is_some() {
                return Ok(None);
            }

            current_node = self.graph.edge_endpoints(edge)?.1;
        }

        // If we got here, that means we were able to match all the triggers on the partial path,
        // and so assuming we're on the proper type, we have a direct path from the start node.
        let current_node_weight = self.graph.node_weight(current_node)?;
        let QueryGraphNodeType::SchemaType(type_pos) = &current_node_weight.type_ else {
            return Ok(None);
        };
        Ok(if type_pos == end_type_position {
            Some(current_node)
        } else {
            None
        })
    }
}

/// `BinaryHeap::pop` returns the "greatest" element. We want the one with the fewest edges.
/// This wrapper compares by *reverse* comparison of edge count.
struct HeapElement<TTrigger, TEdge>(Arc<GraphPath<TTrigger, TEdge>>)
where
    TTrigger: Eq + Hash,
    Arc<TTrigger>: Into<GraphPathTrigger>,
    TEdge: Copy + Into<Option<EdgeIndex>>,
    EdgeIndex: Into<TEdge>;

impl<TTrigger, TEdge> PartialEq for HeapElement<TTrigger, TEdge>
where
    TTrigger: Eq + Hash,
    Arc<TTrigger>: Into<GraphPathTrigger>,
    TEdge: Copy + Into<Option<EdgeIndex>>,
    EdgeIndex: Into<TEdge>,
{
    fn eq(&self, other: &HeapElement<TTrigger, TEdge>) -> bool {
        self.0.edges.len() == other.0.edges.len()
    }
}

impl<TTrigger, TEdge> Eq for HeapElement<TTrigger, TEdge>
where
    TTrigger: Eq + Hash,
    Arc<TTrigger>: Into<GraphPathTrigger>,
    TEdge: Copy + Into<Option<EdgeIndex>>,
    EdgeIndex: Into<TEdge>,
{
}

impl<TTrigger, TEdge> PartialOrd for HeapElement<TTrigger, TEdge>
where
    TTrigger: Eq + Hash,
    Arc<TTrigger>: Into<GraphPathTrigger>,
    TEdge: Copy + Into<Option<EdgeIndex>>,
    EdgeIndex: Into<TEdge>,
{
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}

impl<TTrigger, TEdge> Ord for HeapElement<TTrigger, TEdge>
where
    TTrigger: Eq + Hash,
    Arc<TTrigger>: Into<GraphPathTrigger>,
    TEdge: Copy + Into<Option<EdgeIndex>>,
    EdgeIndex: Into<TEdge>,
{
    fn cmp(&self, other: &Self) -> Ordering {
        self.0.edges.len().cmp(&other.0.edges.len()).reverse()
    }
}

impl OpGraphPath {
    fn next_edge_for_field(&self, field: &Field) -> Option<EdgeIndex> {
        self.graph.edge_for_field(self.tail, field)
    }

    fn next_edge_for_inline_fragment(&self, inline_fragment: &InlineFragment) -> Option<EdgeIndex> {
        self.graph
            .edge_for_inline_fragment(self.tail, inline_fragment)
    }

    fn add_field_edge(
        &self,
        operation_field: Field,
        edge: EdgeIndex,
        condition_resolver: &mut impl ConditionResolver,
        context: &OpGraphPathContext,
    ) -> Result<Option<OpGraphPath>, FederationError> {
        let condition_resolution = self.can_satisfy_conditions(
            edge,
            condition_resolver,
            context,
            &Default::default(),
            &Default::default(),
        )?;
        if matches!(condition_resolution, ConditionResolution::Satisfied { .. }) {
            self.add(
                operation_field.into(),
                edge.into(),
                condition_resolution,
                None,
            )
            .map(Some)
        } else {
            Ok(None)
        }
    }

    pub(crate) fn mark_overriding(
        &self,
        others: &[SimultaneousPaths],
    ) -> (OpGraphPath, Vec<SimultaneousPaths>) {
        let new_id = OverrideId::new();
        let mut new_own_path_ids = self.overriding_path_ids.as_ref().clone();
        new_own_path_ids.insert(new_id);
        let new_self = OpGraphPath {
            own_path_ids: Arc::new(new_own_path_ids),
            ..self.clone()
        };
        let new_others = others
            .iter()
            .map(|option| {
                SimultaneousPaths(
                    option
                        .0
                        .iter()
                        .map(|path| {
                            let mut new_overriding_path_ids =
                                path.overriding_path_ids.as_ref().clone();
                            new_overriding_path_ids.insert(new_id);
                            Arc::new(OpGraphPath {
                                overriding_path_ids: Arc::new(new_overriding_path_ids),
                                ..path.as_ref().clone()
                            })
                        })
                        .collect(),
                )
            })
            .collect();
        (new_self, new_others)
    }

    pub(crate) fn is_overridden_by(&self, other: &Self) -> bool {
        self.overriding_path_ids
            .iter()
            .any(|overriding_id| other.own_path_ids.contains(overriding_id))
    }

    pub(crate) fn subgraph_jumps(&self) -> Result<u32, FederationError> {
        self.subgraph_jumps_at_idx(0)
    }

    fn subgraph_jumps_at_idx(&self, start_index: usize) -> Result<u32, FederationError> {
        self.edges[start_index..]
            .iter()
            .flatten()
            .try_fold(0, |sum, &edge_index| {
                let (start, end) = self.graph.edge_endpoints(edge_index)?;
                let start = self.graph.node_weight(start)?;
                let end = self.graph.node_weight(end)?;
                let changes_subgraph = start.source != end.source;
                Ok(sum + if changes_subgraph { 1 } else { 0 })
            })
    }

    fn find_longest_common_prefix_length(
        &self,
        other: &OpGraphPath,
    ) -> Result<usize, FederationError> {
        if self.head != other.head {
            return Err(FederationError::internal(
                "Paths unexpectedly did not start at the same node.",
            ));
        }

        Ok(self
            .edges
            .iter()
            .zip(&other.edges)
            .position(|(self_edge, other_edge)| self_edge != other_edge)
            .unwrap_or_else(|| self.edges.len().min(other.edges.len())))
    }

    /// Looks for the longest common prefix for `self` and `other` (assuming that both paths are
    /// built as options for the same "query path"), and then compares whether each path has
    /// subgraph jumps after said prefix.
    ///
    /// Note this method always return something, but the longest common prefix considered may very
    /// well be empty. Also note that this method assumes that the 2 paths have the same root, and
    /// will fail if that's not the case.
    ///
    /// Returns the comparison of whether `self` and `other` have subgraph jumps after said prefix
    /// (e.g. `Ordering::Less` means `self` has zero subgraph jumps after said prefix while `other`
    /// has at least one). If they both have subgraph jumps or neither has subgraph jumps, then we
    /// return `Ordering::Equal`.
    fn compare_subgraph_jumps_after_last_common_node(
        &self,
        other: &OpGraphPath,
    ) -> Result<Ordering, FederationError> {
        let longest_common_prefix_len = self.find_longest_common_prefix_length(other)?;
        let self_jumps = self.subgraph_jumps_at_idx(longest_common_prefix_len)? > 0;
        let other_jumps = other.subgraph_jumps_at_idx(longest_common_prefix_len)? > 0;
        Ok(self_jumps.cmp(&other_jumps))
    }

    pub(crate) fn terminate_with_non_requested_typename_field(
        &self,
    ) -> Result<OpGraphPath, FederationError> {
        // If the last step of the path was a fragment/type-condition, we want to remove it before
        // we get __typename. The reason is that this avoid cases where this method would make us
        // build plans like:
        // {
        //   foo {
        //     __typename
        //     ... on A {
        //       __typename
        //     }
        //     ... on B {
        //       __typename
        //     }
        // }
        // Instead, we just generate:
        // {
        //   foo {
        //     __typename
        //   }
        // }
        // Note it's ok to do this because the __typename we add is _not_ requested, it is just
        // added in cases where we need to ensure a selection is not empty, and so this
        // transformation is fine to do.
        let path = self.truncate_trailing_downcasts()?;
        let tail_weight = self.graph.node_weight(path.tail)?;
        let QueryGraphNodeType::SchemaType(tail_type_pos) = &tail_weight.type_ else {
            return Err(FederationError::internal(
                "Unexpectedly found federated root node as tail",
            ));
        };
        let Ok(tail_type_pos) = CompositeTypeDefinitionPosition::try_from(tail_type_pos.clone())
        else {
            return Ok(path);
        };
        let typename_field = Field::new_introspection_typename(
            self.graph.schema_by_source(&tail_weight.source)?,
            &tail_type_pos,
            None,
        );
        let Some(edge) = self.graph.edge_for_field(path.tail, &typename_field) else {
            return Err(FederationError::internal(
                "Unexpectedly missing edge for __typename field",
            ));
        };
        path.add(
            typename_field.into(),
            Some(edge),
            ConditionResolution::no_conditions(),
            None,
        )
    }

    /// Remove all trailing downcast edges and `None` edges.
    fn truncate_trailing_downcasts(&self) -> Result<OpGraphPath, FederationError> {
        let mut runtime_types = Arc::new(self.head_possible_runtime_types()?);
        let mut last_edge_index = None;
        let mut last_runtime_types = runtime_types.clone();
        for (edge_index, edge) in self.edges.iter().enumerate() {
            runtime_types = Arc::new(
                self.graph
                    .advance_possible_runtime_types(&runtime_types, *edge)?,
            );
            let Some(edge) = edge else {
                continue;
            };
            let edge_weight = self.graph.edge_weight(*edge)?;
            if !matches!(
                edge_weight.transition,
                QueryGraphEdgeTransition::Downcast { .. }
            ) {
                last_edge_index = Some(edge_index);
                last_runtime_types = runtime_types.clone();
            }
        }
        let Some(last_edge_index) = last_edge_index else {
            // PORT_NOTE: The JS codebase just returns the same path if all edges are downcast or
            // `None` edges. This is likely a bug, so we instead return the empty path here.
            return OpGraphPath::new(self.graph.clone(), self.head);
        };
        let prefix_length = last_edge_index + 1;
        if prefix_length == self.edges.len() {
            return Ok(self.clone());
        }
        let Some(last_edge) = self.edges[last_edge_index] else {
            return Err(FederationError::internal(
                "Unexpectedly found None for last non-downcast, non-None edge",
            ));
        };
        let (_, last_edge_tail) = self.graph.edge_endpoints(last_edge)?;
        Ok(OpGraphPath {
            graph: self.graph.clone(),
            head: self.head,
            tail: last_edge_tail,
            edges: self.edges[0..prefix_length].to_vec(),
            edge_triggers: self.edge_triggers[0..prefix_length].to_vec(),
            edge_conditions: self.edge_conditions[0..prefix_length].to_vec(),
            last_subgraph_entering_edge_info: self.last_subgraph_entering_edge_info.clone(),
            own_path_ids: self.own_path_ids.clone(),
            overriding_path_ids: self.overriding_path_ids.clone(),
            runtime_types_of_tail: last_runtime_types,
            runtime_types_before_tail_if_last_is_cast: None,
            // TODO: The JS codebase copied this from the current path, which seems like a bug.
            defer_on_tail: self.defer_on_tail.clone(),
        })
    }

    pub(crate) fn is_equivalent_save_for_type_explosion_to(
        &self,
        other: &OpGraphPath,
    ) -> Result<bool, FederationError> {
        // We're looking at the specific case where both paths are basically equivalent except for a
        // single step of type-explosion, so if either of the paths don't start and end on the
        // same node, or if `other` is not exactly 1 more step than `self`, we're done.
        if !(self.head == other.head
            && self.tail == other.tail
            && self.edges.len() == other.edges.len() - 1)
        {
            return Ok(false);
        }

        // If the above is true, then we find the first difference in the paths.
        let Some(diff_pos) = self
            .edges
            .iter()
            .zip(&other.edges)
            .position(|(self_edge, other_edge)| self_edge != other_edge)
        else {
            // All edges are the same, but the `other` path has an extra edge. This can't be a type
            // explosion + key resolution, so we consider them not equivalent here.
            //
            // PORT_NOTE: The JS codebase returns `true` here, claiming the paths are the same. This
            // isn't true though as we're skipping the last element of `other` in the JS codebase
            // (and while that edge can't change the `tail`, it doesn't mean that `self` subsumes
            // `other`). We fix this bug here by returning `false` instead of `true`.
            return Ok(false);
        };

        // If the first difference is not a "type-explosion", i.e. if `other` is a cast from an
        // interface to one of the implementation, then we're not in the case we're looking for.
        let Some(self_edge) = self.edges[diff_pos] else {
            return Ok(false);
        };
        let Some(other_edge) = self.edges[diff_pos] else {
            return Ok(false);
        };
        let other_edge_weight = other.graph.edge_weight(other_edge)?;
        let QueryGraphEdgeTransition::Downcast {
            from_type_position, ..
        } = &other_edge_weight.transition
        else {
            return Ok(false);
        };
        if !matches!(
            from_type_position,
            CompositeTypeDefinitionPosition::Interface(_)
        ) {
            return Ok(false);
        }

        // At this point, we want both paths to take the "same" key, but because one is starting
        // from the interface while the other one from an implementation, they won't be technically
        // the "same" edge index. So we check that both are key-resolution edges, to the same
        // subgraph and type, and with the same condition.
        let Some(other_next_edge) = self.edges[diff_pos + 1] else {
            return Ok(false);
        };
        let (_, self_edge_tail) = other.graph.edge_endpoints(self_edge)?;
        let self_edge_weight = other.graph.edge_weight(self_edge)?;
        let (_, other_next_edge_tail) = other.graph.edge_endpoints(other_next_edge)?;
        let other_next_edge_weight = other.graph.edge_weight(other_next_edge)?;
        if !(matches!(
            self_edge_weight.transition,
            QueryGraphEdgeTransition::KeyResolution
        ) && matches!(
            other_next_edge_weight.transition,
            QueryGraphEdgeTransition::KeyResolution
        ) && self_edge_tail == other_next_edge_tail
            && self_edge_weight.conditions == other_next_edge_weight.conditions)
        {
            return Ok(false);
        }

        // So far, so good. Check that the rest of the paths are equal. Note that starts with
        // `diff_pos + 1` for `self`, but `diff_pos + 2` for `other` since we looked at two edges
        // there instead of one.
        return Ok(self.edges[(diff_pos + 1)..]
            .iter()
            .zip(other.edges[(diff_pos + 2)..].iter())
            .all(|(self_edge, other_edge)| self_edge == other_edge));
    }

    /// This method is used to detect when using an interface field "directly" could fail (i.e. lead
    /// to a dead end later for the query path) while type-exploding may succeed.
    ///
    /// In general, taking a field from an interface directly or through it's implementation by
    /// type-exploding leads to the same option, and so taking one or the other is more of a matter
    /// of "which is more efficient". But there is a special case where this may not be true, and
    /// this is when all of the following hold:
    /// 1. The interface is implemented by an entity type.
    /// 2. The field being looked at is @shareable.
    /// 3. The field type has a different set of fields (and less fields) in the "current" subgraph
    ///    than in another one.
    ///
    /// For instance, consider if some Subgraph A has this schema:
    /// """
    /// type Query {
    ///   i: I
    /// }
    ///
    /// interface I {
    ///   s: S
    /// }
    ///
    /// type T implements I @key(fields: "id") {
    ///   id: ID!
    ///   s: S @shareable
    /// }
    ///
    /// type S @shareable {
    ///   x: Int
    /// }
    /// """
    /// and if some Subgraph B has this schema:
    /// """
    /// type T @key(fields: "id") {
    ///   id: ID!
    ///   s: S @shareable
    /// }
    ///
    /// type S @shareable {
    ///   x: Int
    ///   y: Int
    /// }
    /// """
    /// and suppose that `{ i { s { y } } }` is queried. If we follow `I.s` in subgraph A then the
    /// `y` field cannot be found, because `S` not being an entity means we cannot "jump" to
    /// subgraph B (even if it was, there may not be a usable key to jump between the 2 subgraphs).
    /// However, if we "type-explode" into implementation `T`, then we can jump to subgraph B from
    /// that, at which point we can reach `y`.
    ///
    /// So the goal of this method is to detect when we might be in such a case: when we are, we
    /// will have to consider type explosion on top of the direct route in case that direct route
    /// ends up "not panning out" (note that by the time this method is called, we're only looking
    /// at the options for type `I.s`; we do not know yet if `y` is queried next and so cannot tell
    /// if type explosion will be necessary or not).
    // PORT_NOTE: In the JS code, this method was a free-standing function called "anImplementationIsEntityWithFieldShareable".
    fn has_an_entity_implementation_with_shareable_field(
        &self,
        _source: &NodeStr,
        itf: InterfaceFieldDefinitionPosition,
    ) -> Result<bool, FederationError> {
        let valid_schema = self.graph.schema()?;
        let schema = valid_schema.schema();
        let fed_spec = get_federation_spec_definition_from_subgraph(valid_schema)?;
        let key_directive = fed_spec.key_directive_definition(valid_schema)?;
        let shareable_directive = fed_spec.shareable_directive(valid_schema)?;
        let comp_type_pos = CompositeTypeDefinitionPosition::Interface(itf.parent());
        for implem in valid_schema.possible_runtime_types(comp_type_pos)? {
            let ty = implem.get(schema)?;
            let field = ty.fields.get(&itf.field_name).ok_or_else(|| {
                FederationError::internal(
                    "Unable to find interface field ({itf}) in schema: {schema}",
                )
            })?;
            if !ty.directives.has(&key_directive.name) {
                continue;
            }
            if !field.directives.has(&shareable_directive.name) {
                continue;
            }

            // Returning `true` for this method has a cost: it will make us consider type-explosion for `itf`, and this can
            // sometime lead to a large number of additional paths to explore, which can have a substantial cost. So we want
            // to limit it if we can avoid it. As it happens, we should return `true` if it is possible that "something"
            // (some field) in the type of `field` is reachable in _another_ subgraph but no in the one of the current path.
            // And while it's not trivial to check this in general, there are some easy cases we can eliminate. For instance,
            // if the type in the current subgraph has only leaf fields, we can check that all other subgraphs reachable
            // from the implementation have the same set of leaf fields.
            let base_ty_name = field.ty.inner_named_type();
            if is_leaf_type(schema, base_ty_name) {
                continue;
            }
            let Some(ty) = schema.get_object(base_ty_name) else {
                return Ok(true);
            };
            if ty
                .fields
                .values()
                .any(|f| !is_leaf_type(schema, f.ty.inner_named_type()))
            {
                return Ok(true);
            }
            for node in self.graph.nodes_for_type(&ty.name) {
                let node = self.graph.node_weight(node)?;
                let tail = self.graph.node_weight(self.tail)?;
                if node.source == tail.source {
                    continue;
                }
                let Some(src) = self.graph.sources.get(&node.source) else {
                    return Err(FederationError::internal(format!(
                        "{node} has no valid schema in QueryGraph: {:?}",
                        self.graph
                    )));
                };
                let fed_spec = get_federation_spec_definition_from_subgraph(src)?;
                let shareable_directive = fed_spec.shareable_directive(src)?;
                let build_err = || {
                    Err(FederationError::internal(format!(
                        "{implem} is an object in {} but a {} in {}",
                        tail.source, node.type_, node.source
                    )))
                };
                let QueryGraphNodeType::SchemaType(node_ty) = &node.type_ else {
                    return build_err();
                };
                let node_ty = node_ty.get(schema)?;
                let other_fields = match node_ty {
                    ExtendedType::Object(obj) => &obj.fields,
                    ExtendedType::Interface(int) => &int.fields,
                    _ => return build_err(),
                };
                let Some(field) = other_fields.get(&itf.field_name) else {
                    continue;
                };
                if !field.directives.has(&shareable_directive.name) {
                    continue;
                }
                let field_ty = field.ty.inner_named_type();
                if field_ty != base_ty_name
                    || !(schema.get_object(field_ty).is_some()
                        || schema.get_interface(field_ty).is_some())
                {
                    // We have a genuine difference here, so we should explore type explosion.
                    return Ok(true);
                }
                let names: HashSet<_> = other_fields.keys().collect();
                if !ty.fields.keys().all(|f| names.contains(&f)) {
                    // Same, we have a genuine difference.
                    return Ok(true);
                }
            }
            return Ok(false);
        }
        Ok(false)
    }

    /// For the first element of the pair, the data has the same meaning as in
    /// `SimultaneousPathsWithLazyIndirectPaths.advance_with_operation_element()`. We also actually
    /// need to return a `Vec` of options of simultaneous paths (because when we type explode, we
    /// create simultaneous paths, but as a field might be resolved by multiple subgraphs, we may
    /// have also created multiple options).
    ///
    /// For the second element, it is true if the result only has type-exploded results.
    fn advance_with_operation_element(
        &self,
        supergraph_schema: ValidFederationSchema,
        operation_element: &OpPathElement,
        context: &OpGraphPathContext,
        condition_resolver: &mut impl ConditionResolver,
    ) -> Result<(Option<Vec<SimultaneousPaths>>, Option<bool>), FederationError> {
        let tail_weight = self.graph.node_weight(self.tail)?;
        let QueryGraphNodeType::SchemaType(tail_type_pos) = &tail_weight.type_ else {
            // We cannot advance any operation from here. We need to take the initial non-collecting
            // edges first.
            return Ok((None, None));
        };
        match operation_element {
            OpPathElement::Field(operation_field) => {
                match tail_type_pos {
                    OutputTypeDefinitionPosition::Object(tail_type_pos) => {
                        // Just take the edge corresponding to the field, if it exists and can be
                        // used.
                        let Some(edge) = self.next_edge_for_field(operation_field) else {
                            return Ok((None, None));
                        };

                        // If the tail type is an `@interfaceObject`, it's possible that the
                        // requested field is a field of an implementation of the interface. Because
                        // we found an edge, we know that the interface object has the field and we
                        // can use the edge. However, we can't add the operation field as-is to this
                        // path, since it's referring to a parent type that is not in the current
                        // subgraph. We must instead use the tail's type, so we change the field
                        // accordingly.
                        //
                        // TODO: It would be good to understand what parts of query planning rely
                        // on triggers being valid within a subgraph.
                        let mut operation_field = operation_field.clone();
                        if self.tail_is_interface_object()?
                            && *operation_field.data().field_position.type_name()
                                != tail_type_pos.type_name
                        {
                            let field_on_tail_type = tail_type_pos
                                .field(operation_field.data().field_position.field_name().clone());
                            if field_on_tail_type
                                .try_get(self.graph.schema_by_source(&tail_weight.source)?.schema())
                                .is_none()
                            {
                                let edge_weight = self.graph.edge_weight(edge)?;
                                return Err(FederationError::internal(format!(
                                    "Unexpectedly missing {} for {} from path {}",
                                    operation_field, edge_weight, self,
                                )));
                            }
                            operation_field = Field::new(FieldData {
                                schema: self.graph.schema_by_source(&tail_weight.source)?.clone(),
                                field_position: field_on_tail_type.into(),
                                alias: operation_field.data().alias.clone(),
                                arguments: operation_field.data().arguments.clone(),
                                directives: operation_field.data().directives.clone(),
                                sibling_typename: operation_field.data().sibling_typename.clone(),
                            })
                        }

                        let field_path = self.add_field_edge(
                            operation_field,
                            edge,
                            condition_resolver,
                            context,
                        )?;
                        Ok((field_path.map(|p| vec![p.into()]), None))
                    }
                    OutputTypeDefinitionPosition::Interface(tail_type_pos) => {
                        // Due to `@interfaceObject`, we could be in a case where the field asked is
                        // not on the interface but rather on one of it's implementations. This can
                        // happen if we just entered the subgraph on an interface `@key` and are
                        // and coming from an `@interfaceObject`. In that case, we'll skip checking
                        // for a direct interface edge and simply cast into that implementation
                        // below.
                        let field_is_of_an_implementation =
                            *operation_field.data().field_position.type_name()
                                != tail_type_pos.type_name;

                        // First, we check if there is a direct edge from the interface (which only
                        // happens if we're in a subgraph that knows all of the implementations of
                        // that interface globally and all of them resolve the field). If there is
                        // one, then we have 2 options:
                        //  - We take that edge.
                        //  - We type-explode (like when we don't have a direct interface edge).
                        // We want to avoid looking at both options if we can because it multiplies
                        // planning work quickly if we always check both options. And in general,
                        // taking the interface edge is better than type explosion "if it works",
                        // so we distinguish a number of cases where we know that either:
                        // - Type-exploding cannot work unless taking the interface edge also does
                        //   (the `has_an_entity_implementation_with_shareable_field()` call).
                        // - Type-exploding cannot be more efficient than the direct path (when no
                        //   `@provides` are involved; if a `@provides` is involved in one of the
                        //    implementations, then type-exploding may lead to a shorter overall
                        //    plan thanks to that `@provides`).
                        let interface_edge = if field_is_of_an_implementation {
                            None
                        } else {
                            self.next_edge_for_field(operation_field)
                        };
                        let interface_path = if let Some(interface_edge) = &interface_edge {
                            let field_path = self.add_field_edge(
                                operation_field.clone(),
                                *interface_edge,
                                condition_resolver,
                                context,
                            )?;
                            if field_path.is_none() {
                                let interface_edge_weight =
                                    self.graph.edge_weight(*interface_edge)?;
                                return Err(FederationError::internal(format!(
                                    "Interface edge {} unexpectedly had conditions",
                                    interface_edge_weight
                                )));
                            }
                            field_path
                        } else {
                            None
                        };
                        let direct_path_overrides_type_explosion =
                            if let Some(interface_edge) = &interface_edge {
                                // There are 2 separate cases where we going to do both "direct" and
                                // "type-exploding" options:
                                // 1. There is an `@provides`: in that case the "type-exploding
                                //    case can legitimately be more efficient and we want to =
                                //    consider it "all the way"
                                // 2. In the sub-case of
                                //    `!has_an_entity_implementation_with_shareable_field(...)`,
                                //    where we want to have the type-exploding option only for the
                                //    case where the "direct" one fails later. But in that case,
                                //    we'll remember that if the direct option pans out, then we can
                                //    ignore the type-exploding one.
                                // `direct_path_overrides_type_explosion` indicates that we're in
                                // the 2nd case above, not the 1st one.
                                operation_field
                                    .data()
                                    .field_position
                                    .is_introspection_typename_field()
                                    || (!self.graph.is_provides_edge(*interface_edge)?
                                        && !self.graph.has_an_implementation_with_provides(
                                            &tail_weight.source,
                                            tail_type_pos.field(
                                                operation_field
                                                    .data()
                                                    .field_position
                                                    .field_name()
                                                    .clone(),
                                            ),
                                        )?)
                            } else {
                                false
                            };
                        if direct_path_overrides_type_explosion {
                            // We can special-case terminal (leaf) fields: as long they have no
                            // `@provides`, then the path ends there and there is no need to check
                            // type explosion "in case the direct path doesn't pan out".
                            // Additionally, if we're not in the case where an implementation
                            // is an entity with a shareable field, then there is no case where the
                            // direct case wouldn't "pan out" but the type explosion would, so we
                            // can ignore type-exploding there too.
                            //
                            // TODO: We should re-assess this when we support `@requires` on
                            // interface fields (typically, should we even try to type-explode
                            // if the direct edge cannot be satisfied? Probably depends on the exact
                            // semantics of `@requires` on interface fields).
                            let operation_field_type_name = operation_field
                                .data()
                                .field_position
                                .get(operation_field.data().schema.schema())?
                                .ty
                                .inner_named_type();
                            let is_operation_field_type_leaf = matches!(
                                operation_field
                                    .data()
                                    .schema
                                    .get_type(operation_field_type_name.clone())?,
                                TypeDefinitionPosition::Scalar(_) | TypeDefinitionPosition::Enum(_)
                            );
                            if is_operation_field_type_leaf
                                && self.has_an_entity_implementation_with_shareable_field(
                                    &tail_weight.source,
                                    tail_type_pos.field(
                                        operation_field.data().field_position.field_name().clone(),
                                    ),
                                )?
                            {
                                let Some(interface_path) = interface_path else {
                                    return Err(FederationError::internal(
                                        "Unexpectedly missing interface path",
                                    ));
                                };
                                return Ok((Some(vec![interface_path.into()]), None));
                            }
                        }

                        // There are 2 main cases to handle here:
                        // - The most common is that it's a field of the interface that is queried,
                        //   and so we should type-explode because either we didn't had a direct
                        //   edge, or `@provides` makes it potentially worthwhile to check with type
                        //   explosion.
                        // - But, as mentioned earlier, we could be in the case where the field
                        //   queried is actually of one of the implementation of the interface. In
                        //   that case, we only want to consider that one implementation.
                        let implementations = if field_is_of_an_implementation {
                            let CompositeTypeDefinitionPosition::Object(field_parent_pos) =
                                &operation_field.data().field_position.parent()
                            else {
                                return Err(FederationError::internal(
                                        format!(
                                            "{} requested on {}, but field's parent {} is not an object type",
                                            operation_field.data().field_position,
                                            tail_type_pos,
                                            operation_field.data().field_position.type_name()
                                        )
                                    ));
                            };
                            if !self.runtime_types_of_tail.contains(field_parent_pos) {
                                return Err(FederationError::internal(
                                    format!(
                                        "{} requested on {}, but field's parent {} is not an implementation type",
                                        operation_field.data().field_position,
                                        tail_type_pos,
                                        operation_field.data().field_position.type_name()
                                    )
                                ));
                            }
                            Arc::new(IndexSet::from([field_parent_pos.clone()]))
                        } else {
                            self.runtime_types_of_tail.clone()
                        };

                        // We type-explode. For all implementations, we need to call
                        // `advance_with_operation_element()` on a made-up inline fragment. If
                        // any gives us empty options, we bail.
                        let mut options_for_each_implementation = vec![];
                        for implementation_type_pos in implementations.as_ref() {
                            let implementation_inline_fragment =
                                InlineFragment::new(InlineFragmentData {
                                    schema: self
                                        .graph
                                        .schema_by_source(&tail_weight.source)?
                                        .clone(),
                                    parent_type_position: tail_type_pos.clone().into(),
                                    type_condition_position: Some(
                                        implementation_type_pos.clone().into(),
                                    ),
                                    directives: Default::default(),
                                    selection_id: SelectionId::new(),
                                });
                            let implementation_options =
                                SimultaneousPathsWithLazyIndirectPaths::new(
                                    self.clone().into(),
                                    context.clone(),
                                    Default::default(),
                                    Default::default(),
                                )
                                .advance_with_operation_element(
                                    supergraph_schema.clone(),
                                    &implementation_inline_fragment.into(),
                                    condition_resolver,
                                )?;
                            // If we find no options for that implementation, we bail (as we need to
                            // simultaneously advance all implementations).
                            let Some(mut implementation_options) = implementation_options else {
                                return Ok((interface_path.map(|p| vec![p.into()]), None));
                            };
                            // If the new inline fragment makes it so that we're on an unsatisfiable
                            // branch, we just ignore that implementation.
                            if implementation_options.is_empty() {
                                continue;
                            }
                            // For each option, we call `advance_with_operation_element()` again on
                            // our own operation element (the field), which gives us some options
                            // (or not and we bail).
                            let mut field_options = vec![];
                            for implementation_option in &mut implementation_options {
                                let field_options_for_implementation = implementation_option
                                    .advance_with_operation_element(
                                        supergraph_schema.clone(),
                                        operation_element,
                                        condition_resolver,
                                    )?;
                                let Some(field_options_for_implementation) =
                                    field_options_for_implementation
                                else {
                                    continue;
                                };
                                // Advancing a field should never get us into an unsatisfiable
                                // condition (only fragments can).
                                if field_options_for_implementation.is_empty() {
                                    return Err(FederationError::internal(format!(
                                        "Unexpected unsatisfiable path after {}",
                                        operation_field
                                    )));
                                }
                                field_options.extend(
                                    field_options_for_implementation
                                        .into_iter()
                                        .map(|s| s.paths),
                                );
                            }
                            // If we find no options to advance that implementation, we bail (as we
                            // need to simultaneously advance all implementations).
                            if field_options.is_empty() {
                                return Ok((interface_path.map(|p| vec![p.into()]), None));
                            };
                            options_for_each_implementation.push(field_options);
                        }
                        let all_options = SimultaneousPaths::flat_cartesian_product(
                            options_for_each_implementation,
                        );
                        if let Some(interface_path) = interface_path {
                            let (interface_path, all_options) =
                                if direct_path_overrides_type_explosion {
                                    interface_path.mark_overriding(&all_options)
                                } else {
                                    (interface_path, all_options)
                                };
                            Ok((
                                Some(
                                    vec![interface_path.into()]
                                        .into_iter()
                                        .chain(all_options)
                                        .collect(),
                                ),
                                None,
                            ))
                        } else {
                            // TODO: This appears to be the only place returning non-None for the
                            // 2nd argument, so this could be Option<(Vec<SimultaneousPaths>, bool)>
                            // instead.
                            Ok((Some(all_options), Some(true)))
                        }
                    }
                    OutputTypeDefinitionPosition::Union(_) => {
                        let Some(typename_edge) = self.next_edge_for_field(operation_field) else {
                            return Err(FederationError::internal(
                                "Should always have an edge for __typename edge on an union",
                            ));
                        };
                        let field_path = self.add_field_edge(
                            operation_field.clone(),
                            typename_edge,
                            condition_resolver,
                            context,
                        )?;
                        Ok((field_path.map(|p| vec![p.into()]), None))
                    }
                    _ => {
                        // Only object, interfaces, and unions (only for __typename) have fields, so
                        // the query should have been flagged invalid if a field was selected on
                        // something else.
                        Err(FederationError::internal(format!(
                            "Unexpectedly found field {} on non-composite type {}",
                            operation_field, tail_type_pos,
                        )))
                    }
                }
            }
            OpPathElement::InlineFragment(operation_inline_fragment) => {
                let type_condition_name = operation_inline_fragment
                    .data()
                    .type_condition_position
                    .as_ref()
                    .map(|pos| pos.type_name())
                    .unwrap_or_else(|| tail_type_pos.type_name())
                    .clone();
                if type_condition_name == *tail_type_pos.type_name() {
                    // If there is no type condition (or the condition is the type we're already
                    // on), it means we're essentially just applying some directives (could be a
                    // `@skip`/`@include` for instance). This doesn't make us take any edge, but if
                    // the operation element does has directives, we record it.
                    let fragment_path = if operation_inline_fragment.data().directives.is_empty() {
                        self.clone()
                    } else {
                        self.add(
                            operation_inline_fragment.clone().into(),
                            None,
                            ConditionResolution::no_conditions(),
                            operation_inline_fragment
                                .data()
                                .defer_directive_arguments()?,
                        )?
                    };
                    return Ok((Some(vec![fragment_path.into()]), None));
                }
                match tail_type_pos {
                    OutputTypeDefinitionPosition::Interface(_)
                    | OutputTypeDefinitionPosition::Union(_) => {
                        let tail_type_pos: AbstractTypeDefinitionPosition =
                            tail_type_pos.clone().try_into()?;

                        // If we have an edge for the typecast, take that.
                        if let Some(edge) =
                            self.next_edge_for_inline_fragment(operation_inline_fragment)
                        {
                            let edge_weight = self.graph.edge_weight(edge)?;
                            if edge_weight.conditions.is_some() {
                                return Err(FederationError::internal(
                                    "Unexpectedly found condition on inline fragment collecting edge"
                                ));
                            }
                            let fragment_path = self.add(
                                operation_inline_fragment.clone().into(),
                                Some(edge),
                                ConditionResolution::no_conditions(),
                                operation_inline_fragment
                                    .data()
                                    .defer_directive_arguments()?,
                            )?;
                            return Ok((Some(vec![fragment_path.into()]), None));
                        }

                        // Otherwise, check what the intersection is between the possible runtime
                        // types of the tail type and the ones of the typecast. We need to be able
                        // to go into all those types simultaneously (a.k.a. type explosion).
                        let from_types = self.runtime_types_of_tail.clone();
                        let to_types = supergraph_schema.possible_runtime_types(
                            supergraph_schema
                                .get_type(type_condition_name.clone())?
                                .try_into()?,
                        )?;
                        let intersection = from_types.intersection(&to_types);
                        let mut options_for_each_implementation = vec![];
                        for implementation_type_pos in intersection {
                            let implementation_inline_fragment =
                                InlineFragment::new(InlineFragmentData {
                                    schema: self
                                        .graph
                                        .schema_by_source(&tail_weight.source)?
                                        .clone(),
                                    parent_type_position: tail_type_pos.clone().into(),
                                    type_condition_position: Some(
                                        implementation_type_pos.clone().into(),
                                    ),
                                    directives: operation_inline_fragment.data().directives.clone(),
                                    selection_id: SelectionId::new(),
                                });
                            let implementation_options =
                                SimultaneousPathsWithLazyIndirectPaths::new(
                                    self.clone().into(),
                                    context.clone(),
                                    Default::default(),
                                    Default::default(),
                                )
                                .advance_with_operation_element(
                                    supergraph_schema.clone(),
                                    &implementation_inline_fragment.into(),
                                    condition_resolver,
                                )?;
                            let Some(implementation_options) = implementation_options else {
                                return Ok((None, None));
                            };
                            // If the new inline fragment makes it so that we're on an unsatisfiable
                            // branch, we just ignore that implementation.
                            if implementation_options.is_empty() {
                                continue;
                            }
                            options_for_each_implementation.push(
                                implementation_options
                                    .into_iter()
                                    .map(|s| s.paths)
                                    .collect(),
                            )
                        }
                        let all_options = SimultaneousPaths::flat_cartesian_product(
                            options_for_each_implementation,
                        );
                        Ok((Some(all_options), None))
                    }
                    OutputTypeDefinitionPosition::Object(tail_type_pos) => {
                        // We've already handled the case of a fragment whose type condition is the
                        // same as the tail type. But the fragment might be for either:
                        // - A super-type of the tail type. In which case, we're pretty much in the
                        //   same case than if there were no particular type condition.
                        // - If the tail type is an `@interfaceObject`, then this can be an
                        //   implementation type of the interface in the supergraph. In that case,
                        //   the type condition is not a known type of the subgraph, but the
                        //   subgraph might still be able to handle some of fields, so in that case,
                        //   we essentially "ignore" the fragment for now. We will re-add it back
                        //   later for fields that are not in the current subgraph after we've taken
                        //   an `@key` for the interface.
                        // - An incompatible type. This can happen for a type that intersects a
                        //   super-type of the tail type (since GraphQL allows a fragment as long as
                        //   there is an intersection). In that case, the whole operation element
                        //   simply cannot ever return anything.
                        let type_condition_pos = supergraph_schema.get_type(type_condition_name)?;
                        let abstract_type_condition_pos: Option<AbstractTypeDefinitionPosition> =
                            type_condition_pos.clone().try_into().ok();
                        if let Some(type_condition_pos) = abstract_type_condition_pos {
                            if supergraph_schema
                                .possible_runtime_types(type_condition_pos.clone().into())?
                                .contains(tail_type_pos)
                            {
                                // Type condition is applicable on the tail type, so the types are
                                // already exploded but the condition can reference types from the
                                // supergraph that are not present in the local subgraph.
                                //
                                // If the operation element has applied directives we need to
                                // convert it to an inline fragment without type condition,
                                // otherwise we ignore the fragment altogether.
                                if operation_inline_fragment.data().directives.is_empty() {
                                    return Ok((Some(vec![self.clone().into()]), None));
                                }
                                let operation_inline_fragment =
                                    InlineFragment::new(InlineFragmentData {
                                        schema: self
                                            .graph
                                            .schema_by_source(&tail_weight.source)?
                                            .clone(),
                                        parent_type_position: tail_type_pos.clone().into(),
                                        type_condition_position: None,
                                        directives: operation_inline_fragment
                                            .data()
                                            .directives
                                            .clone(),
                                        selection_id: SelectionId::new(),
                                    });
                                let defer_directive_arguments = operation_inline_fragment
                                    .data()
                                    .defer_directive_arguments()?;
                                let fragment_path = self.add(
                                    operation_inline_fragment.into(),
                                    None,
                                    ConditionResolution::no_conditions(),
                                    defer_directive_arguments,
                                )?;
                                return Ok((Some(vec![fragment_path.into()]), None));
                            }
                        }

                        if self.tail_is_interface_object()? {
                            let mut fake_downcast_edge = None;
                            for edge in self.next_edges()? {
                                let edge_weight = self.graph.edge_weight(edge)?;
                                let QueryGraphEdgeTransition::InterfaceObjectFakeDownCast {
                                    to_type_name,
                                    ..
                                } = &edge_weight.transition
                                else {
                                    continue;
                                };
                                if type_condition_pos.type_name() == to_type_name {
                                    fake_downcast_edge = Some(edge);
                                    break;
                                };
                            }
                            if let Some(fake_downcast_edge) = fake_downcast_edge {
                                let condition_resolution = self.can_satisfy_conditions(
                                    fake_downcast_edge,
                                    condition_resolver,
                                    context,
                                    &Default::default(),
                                    &Default::default(),
                                )?;
                                if matches!(
                                    condition_resolution,
                                    ConditionResolution::Unsatisfied { .. }
                                ) {
                                    return Ok((None, None));
                                }
                                let fragment_path = self.add(
                                    operation_inline_fragment.clone().into(),
                                    Some(fake_downcast_edge),
                                    condition_resolution,
                                    operation_inline_fragment
                                        .data()
                                        .defer_directive_arguments()?,
                                )?;
                                return Ok((Some(vec![fragment_path.into()]), None));
                            }
                        }

                        // The operation element we're dealing with can never return results (the
                        // type conditions applied have no intersection). This means we can fulfill
                        // this operation element (by doing nothing and returning an empty result),
                        // which we indicate by return ingan empty list of options.
                        Ok((Some(vec![]), None))
                    }
                    _ => {
                        // We shouldn't have a fragment on a non-composite type.
                        Err(FederationError::internal(format!(
                            "Unexpectedly found inline fragment {} on non-composite type {}",
                            operation_inline_fragment, tail_type_pos,
                        )))
                    }
                }
            }
        }
    }

    /// Given an `OpGraphPath` and a `SimultaneousPaths` that represent 2 different options to reach
    /// the same query leaf field, checks if one can be shown to be always "better" (more
    /// efficient/optimal) than the other one, regardless of any surrounding context (i.e.
    /// regardless of what the rest of the query plan would be for any other query leaf field).
    ///
    /// Returns the comparison of the complexity of `self` and `other` (e.g. `Ordering::Less` means
    /// `self` is better/has less complexity than `other`). If we can't guarantee anything (at least
    /// "out of context"), then we return `Ordering::Equal`.
    fn compare_single_vs_multi_path_options_complexity_out_of_context(
        &self,
        other: &SimultaneousPaths,
    ) -> Result<Ordering, FederationError> {
        // This handles the same case as the single-path-only case, but compares the single path
        // against each path of the `SimultaneousPaths`, and only "ignores" the `SimultaneousPaths`
        // if all its paths can be ignored.
        //
        // Note that this happens less often than the single-path-only case, but with `@provides` on
        // an interface, you can have cases where on one hand you can get something completely on
        // the current subgraph, but the type-exploded case has to still be generated due to the
        // leaf field not being the one just after the "provided" interface.
        for other_path in other.0.iter() {
            // Note: Not sure if it is possible for a path of the `SimultaneousPaths` option to
            // subsume the single-path one in practice, but if it does, we ignore it because it's
            // not obvious that this is enough to get rid of `self` (maybe if `self` is provably a
            // bit costlier than one of the paths of `other`, but `other` may have many paths and
            // could still be collectively worst than `self`).
            if self.compare_single_path_options_complexity_out_of_context(other_path)?
                != Ordering::Less
            {
                return Ok(Ordering::Equal);
            }
        }
        Ok(Ordering::Less)
    }

    /// Given 2 `OpGraphPath`s that represent 2 different paths to reach the same query leaf field,
    /// checks if one can be shown to be always "better" (more efficient/optimal) than the other
    /// one, regardless of any surrounding context (i.e. regardless of what the rest of the query
    /// plan would be for any other query leaf field).
    ///
    /// Returns the comparison of the complexity of `self` and `other` (e.g. `Ordering::Less` means
    /// `self` is better/has less complexity than `other`). If we can't guarantee anything (at least
    /// "out of context"), then we return `Ordering::Equal`.
    fn compare_single_path_options_complexity_out_of_context(
        &self,
        other: &OpGraphPath,
    ) -> Result<Ordering, FederationError> {
        // Currently, this method only handles the case where we have something like:
        //  -  `self`: <some prefix> -[t]-> T(A)               -[u]-> U(A) -[x] -> Int(A)
        //  - `other`: <some prefix> -[t]-> T(A) -[key]-> T(B) -[u]-> U(B) -[x] -> Int(B)
        // That is, where we have 2 choices that are identical up to the "end", when one stays in
        // the subgraph (`self`, which stays in A) while the other uses a key to get to another
        // subgraph (`other`, going to B).
        //
        // In such a case, whatever else the query plan might be doing, it can never be "worse"
        // to use `self` than to use `other` because both will force the same "fetch dependency
        // graph node" up to the end, but `other` may force one more fetch that `self` does not.
        // Do note that we say "may" above, because the rest of the query plan may very well have a
        // forced choice like:
        //  - `option`: <some prefix> -[t]-> T(A) -[key]-> T(B) -[u]-> U(B) -[y] -> Int(B)
        // in which case the query plan will have the jump from A to B after `t` regardless of
        // whether we use `self` or `other`, but while in that particular case `self` and `other`
        // are about comparable in terms of performance, `self` is still not worse than `other` (and
        // in other situations, `self` may be genuinely be better).
        //
        // Note that this is in many ways just a generalization of a heuristic we use earlier for
        // leaf fields. That is, we will never get as input to this method something like:
        //  -  `self`: <some prefix> -[t]-> T(A)               -[x] -> Int(A)
        //  - `other`: <some prefix> -[t]-> T(A) -[key]-> T(B) -[x] -> Int(B)
        // because when the code is asked for the options for `x` after `<some prefix> -[t]-> T(A)`,
        // it notices that `x` is a leaf and is in `A`, so it doesn't ever look for alternative
        // paths. But this only works for direct leaves of an entity. In the example at the start,
        // field `u` makes this not work, because when we compute choices for `u`, we don't yet know
        // what comes after that, and so we have to take the option of going to subgraph `B` into
        // account (it may very well be that whatever comes after `u` is not in `A`, for instance).
        let self_tail_weight = self.graph.node_weight(self.tail)?;
        let other_tail_weight = self.graph.node_weight(other.tail)?;
        if self_tail_weight.source == other_tail_weight.source {
            // As described above, we want to know if one of the paths has no jumps at all (after
            // the common prefix) while the other has some.
            self.compare_subgraph_jumps_after_last_common_node(other)
        } else {
            Ok(Ordering::Equal)
        }
    }
}

impl Display for OpGraphPath {
    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
        // If the path is length is 0 return "[]"
        // Traverse the path, getting the of the edge.
        let head = &self.graph.graph()[self.head];
        if head.root_kind.is_some() && self.edges.is_empty() {
            return write!(f, "_");
        }
        if head.root_kind.is_some() {
            write!(f, "{head}")?;
        }
        self.edges
            .iter()
            .cloned()
            .enumerate()
            .try_for_each(|(i, e)| match e {
                Some(e) => {
                    let tail = self.graph.graph().edge_endpoints(e).unwrap().1;
                    let node = &self.graph.graph()[tail];
                    let edge = &self.graph.graph()[e];
                    let label = edge.transition.to_string();
                    write!(f, " --[{label}]--> {node}")
                }
                None => write!(f, " ({}) ", self.edge_triggers[i].as_ref()),
            })?;
        if let Some(label) = self.defer_on_tail.as_ref().and_then(|d| d.label()) {
            write!(f, "<defer='{label}'>")?;
        }
        if !self.runtime_types_of_tail.is_empty() {
            write!(f, " (types: [")?;
            for ty in self.runtime_types_of_tail.iter() {
                write!(f, "{ty}")?;
            }
            write!(f, "])")?;
        }
        Ok(())
    }
}

impl SimultaneousPaths {
    /// Given options generated for the advancement of each path of a `SimultaneousPaths`, generate
    /// the options for the `SimultaneousPaths` as a whole.
    fn flat_cartesian_product(
        options_for_each_path: Vec<Vec<SimultaneousPaths>>,
    ) -> Vec<SimultaneousPaths> {
        // This can be written more tersely with a bunch of `reduce()`/`flat_map()`s and friends,
        // but when interfaces type-explode into many implementations, this can end up with fairly
        // large `Vec`s and be a bottleneck, and a more iterative version that pre-allocates `Vec`s
        // is quite a bit faster.
        if options_for_each_path.is_empty() {
            return vec![];
        }

        // Track, for each path, which option index we're at.
        let mut option_indexes = vec![0; options_for_each_path.len()];

        // Pre-allocate `Vec` for the result.
        let num_options = options_for_each_path
            .iter()
            .map(|options| options.len())
            .product();
        let mut product = Vec::with_capacity(num_options);

        // Compute the cartesian product.
        for _ in 0..num_options {
            let num_simultaneous_paths = options_for_each_path
                .iter()
                .zip(&option_indexes)
                .map(|(options, option_index)| options[*option_index].0.len())
                .sum();
            let mut simultaneous_paths = Vec::with_capacity(num_simultaneous_paths);

            for (options, option_index) in options_for_each_path.iter().zip(&option_indexes) {
                simultaneous_paths.extend(options[*option_index].0.iter().cloned());
            }
            product.push(SimultaneousPaths(simultaneous_paths));

            for (options, option_index) in options_for_each_path.iter().zip(&mut option_indexes) {
                if *option_index == options.len() - 1 {
                    *option_index = 0
                } else {
                    *option_index += 1;
                    break;
                }
            }
        }

        product
    }

    /// Given 2 `SimultaneousPaths` that represent 2 different options to reach the same query leaf
    /// field, checks if one can be shown to be always "better" (more efficient/optimal) than the
    /// other one, regardless of any surrounding context (i.e. regardless of what the rest of the
    /// query plan would be for any other query leaf field).
    ///
    /// Note that this method is used on the final options of a given "query path", so all the
    /// heuristics done within `GraphPath` to avoid unnecessary options have already been applied
    /// (e.g. avoiding the consideration of paths that do 2 successive key jumps when there is a
    /// 1-jump equivalent), so this focus on what can be done is based on the fact that the path
    /// considered is "finished".
    ///
    /// Returns the comparison of the complexity of `self` and `other` (e.g. `Ordering::Less` means
    /// `self` is better/has less complexity than `other`). If we can't guarantee anything (at least
    /// "out of context"), then we return `Ordering::Equal`.
    fn compare_options_complexity_out_of_context(
        &self,
        other: &SimultaneousPaths,
    ) -> Result<Ordering, FederationError> {
        match (self.0.as_slice(), other.0.as_slice()) {
            ([a], [b]) => a.compare_single_path_options_complexity_out_of_context(b),
            ([a], _) => a.compare_single_vs_multi_path_options_complexity_out_of_context(other),
            (_, [b]) => Ok(b
                .compare_single_vs_multi_path_options_complexity_out_of_context(self)?
                .reverse()),
            _ => Ok(Ordering::Equal),
        }
    }
}

impl From<Arc<OpGraphPath>> for SimultaneousPaths {
    fn from(value: Arc<OpGraphPath>) -> Self {
        Self(vec![value])
    }
}

impl From<OpGraphPath> for SimultaneousPaths {
    fn from(value: OpGraphPath) -> Self {
        Self::from(Arc::new(value))
    }
}

impl SimultaneousPathsWithLazyIndirectPaths {
    pub(crate) fn new(
        paths: SimultaneousPaths,
        context: OpGraphPathContext,
        excluded_destinations: ExcludedDestinations,
        excluded_conditions: ExcludedConditions,
    ) -> SimultaneousPathsWithLazyIndirectPaths {
        SimultaneousPathsWithLazyIndirectPaths {
            lazily_computed_indirect_paths: std::iter::repeat_with(|| None)
                .take(paths.0.len())
                .collect(),
            paths,
            context,
            excluded_destinations,
            excluded_conditions,
        }
    }

    /// For a given "input" path (identified by an idx in `paths`), each of its indirect options.
    fn indirect_options(
        &mut self,
        updated_context: &OpGraphPathContext,
        path_index: usize,
        condition_resolver: &mut impl ConditionResolver,
    ) -> Result<OpIndirectPaths, FederationError> {
        // Note that the provided context will usually be one we had during construction (the
        // `updated_context` will be `self.context` updated by whichever operation we're looking at,
        // but only operation elements with a @skip/@include will change the context so it's pretty
        // rare), which is why we save recomputation by caching the computed value in that case, but
        // in case it's different, we compute without caching.
        if *updated_context != self.context {
            self.compute_indirect_paths(path_index, condition_resolver)?;
        }
        if let Some(indirect_paths) = &self.lazily_computed_indirect_paths[path_index] {
            Ok(indirect_paths.clone())
        } else {
            let new_indirect_paths = self.compute_indirect_paths(path_index, condition_resolver)?;
            self.lazily_computed_indirect_paths[path_index] = Some(new_indirect_paths.clone());
            Ok(new_indirect_paths)
        }
    }

    fn compute_indirect_paths(
        &self,
        path_index: usize,
        condition_resolver: &mut impl ConditionResolver,
    ) -> Result<OpIndirectPaths, FederationError> {
        self.paths.0[path_index].advance_with_non_collecting_and_type_preserving_transitions(
            &self.context,
            condition_resolver,
            &self.excluded_destinations,
            &self.excluded_conditions,
            // The transitions taken by this method are non-collecting transitions, in which case
            // the trigger is the context (which is really a hack to provide context information for
            // keys during fetch dependency graph updating).
            |_, context| OpGraphPathTrigger::Context(context.clone()),
            |graph, node, trigger| graph.edge_for_op_graph_path_trigger(node, trigger),
        )
    }

    fn create_lazy_options(
        &self,
        options: Vec<SimultaneousPaths>,
        context: OpGraphPathContext,
    ) -> Vec<SimultaneousPathsWithLazyIndirectPaths> {
        options
            .into_iter()
            .map(|paths| {
                SimultaneousPathsWithLazyIndirectPaths::new(
                    paths,
                    context.clone(),
                    self.excluded_destinations.clone(),
                    self.excluded_conditions.clone(),
                )
            })
            .collect()
    }

    /// Returns `None` if the operation cannot be dealt with/advanced. Otherwise, it returns a `Vec`
    /// of options we can be in after advancing the operation, each option being a set of
    /// simultaneous paths in the subgraphs (a single path in the simple case, but type exploding
    /// may make us explore multiple paths simultaneously).
    ///
    /// The lists of options can be empty, which has the special meaning that the operation is
    /// guaranteed to have no results (it corresponds to unsatisfiable conditions), meaning that as
    /// far as query planning goes, we can just ignore the operation but otherwise continue.
    // PORT_NOTE: In the JS codebase, this was named `advanceSimultaneousPathsWithOperation`.
    pub(crate) fn advance_with_operation_element(
        &mut self,
        supergraph_schema: ValidFederationSchema,
        operation_element: &OpPathElement,
        condition_resolver: &mut impl ConditionResolver,
    ) -> Result<Option<Vec<SimultaneousPathsWithLazyIndirectPaths>>, FederationError> {
        let updated_context = self.context.with_context_of(operation_element)?;
        let mut options_for_each_path = vec![];

        // To call the mutating method `indirect_options()`, we need to not hold any immutable
        // references to `self`, which means cloning these paths when iterating.
        let paths = self.paths.0.clone();
        for (path_index, path) in paths.iter().enumerate() {
            let mut options = None;
            let should_reenter_subgraph = path.defer_on_tail.is_some()
                && matches!(operation_element, OpPathElement::Field(_));
            if !should_reenter_subgraph {
                let (advance_options, has_only_type_exploded_results) = path
                    .advance_with_operation_element(
                        supergraph_schema.clone(),
                        operation_element,
                        &updated_context,
                        condition_resolver,
                    )?;
                // If we've got some options, there are a number of cases where there is no point
                // looking for indirect paths:
                // - If the operation element is terminal: this means we just found a direct edge
                //   that is terminal, so no indirect options could be better (this is not true for
                //   non-terminal operation element, where the direct route may end up being a dead
                //   end later). One exception however is when `advanceWithOperationElement()`
                //   type-exploded (meaning that we're on an interface), because in that case, the
                //   type-exploded options have already taken indirect edges into account, so it's
                //   possible that an indirect edge _from the interface_ could be better, but only
                //   if there wasn't a "true" direct edge on the interface, which is what
                //   `has_only_type_exploded_results` tells us.
                // - If we get options, but an empty set of them, which signifies the operation
                //   element corresponds to unsatisfiable conditions and we can essentially ignore
                //   it.
                // - If the operation element is a fragment in general: if we were able to find a
                //   direct option, that means the type is known in the "current" subgraph, and so
                //   we'll still be able to take any indirect edges that we could take now later,
                //   for the follow-up operation element. And pushing the decision will give us more
                //   context and may avoid a bunch of state explosion in practice.
                if let Some(advance_options) = advance_options {
                    if advance_options.is_empty()
                        || (operation_element.is_terminal()?
                            && !has_only_type_exploded_results.unwrap_or(false))
                        || matches!(operation_element, OpPathElement::InlineFragment(_))
                    {
                        // Note that if options is empty, that means this particular "branch" is
                        // unsatisfiable, so we should just ignore it.
                        if !advance_options.is_empty() {
                            options_for_each_path.push(advance_options);
                        }
                        continue;
                    } else {
                        options = Some(advance_options);
                    }
                }
            }

            // If there was not a valid direct path (or we didn't check those because we entered a
            // defer), that's ok, we'll just try with non-collecting edges.
            let mut options = options.unwrap_or_else(Vec::new);
            if let OpPathElement::Field(operation_field) = operation_element {
                // Add whatever options can be obtained by taking some non-collecting edges first.
                let paths_with_non_collecting_edges = self
                    .indirect_options(&updated_context, path_index, condition_resolver)?
                    .filter_non_collecting_paths_for_field(operation_field)?;
                if !paths_with_non_collecting_edges.paths.is_empty() {
                    for paths_with_non_collecting_edges in
                        paths_with_non_collecting_edges.paths.iter()
                    {
                        let (advance_options, _) = paths_with_non_collecting_edges
                            .advance_with_operation_element(
                                supergraph_schema.clone(),
                                operation_element,
                                &updated_context,
                                condition_resolver,
                            )?;
                        // If we can't advance the operation element after that path, ignore it,
                        // it's just not an option.
                        let Some(advance_options) = advance_options else {
                            continue;
                        };
                        // `advance_with_operation_element()` can return an empty `Vec` only if the
                        // operation element is a fragment with a type condition that, on top of the
                        // "current" type is unsatisfiable. But as we've only taken type-preserving
                        // transitions, we cannot get an empty result at this point if we didn't get
                        // one when testing direct transitions above (in which case we would have
                        // exited the method early).
                        if advance_options.is_empty() {
                            return Err(FederationError::internal(format!(
                                "Unexpected empty options after non-collecting path {} for {}",
                                paths_with_non_collecting_edges, operation_element,
                            )));
                        }
                        // There is a special case we can deal with now. Namely, suppose we have a
                        // case where a query is reaching an interface I in a subgraph S1, we query
                        // some field of that interface x, and say that x is provided in subgraph S2
                        // but by an @interfaceObject for I.
                        //
                        // As we look for direct options for I.x in S1 initially, we won't find `x`,
                        // so we will try to type-explode I (let's say into implementations A and
                        // B). And in some cases doing so is necessary, but it may also lead to the
                        // type-exploding option to look like:
                        //  [
                        //    I(S1) -[... on A]-> A(S1) -[key]-> I(S2) -[x] -> Int(S2),
                        //    I(S1) -[... on B]-> B(S1) -[key]-> I(S2) -[x] -> Int(S2),
                        //  ]
                        // But as we look at indirect options now (still from I in S1), we will note
                        // that we can also do:
                        //    I(S1) -[key]-> I(S2) -[x] -> Int(S2),
                        // And while both options are technically valid, the new one really subsumes
                        // the first one: there is no point in type-exploding to take a key to the
                        // same exact subgraph if using the key on the interface directly works.
                        //
                        // So here, we look for that case and remove any type-exploding option that
                        // the new path renders unnecessary. Do note that we only make that check
                        // when the new option is a single-path option, because this gets kind of
                        // complicated otherwise.
                        if paths_with_non_collecting_edges.tail_is_interface_object()? {
                            for indirect_option in &advance_options {
                                if indirect_option.0.len() == 1 {
                                    let mut new_options = vec![];
                                    for option in options {
                                        let mut is_equivalent = true;
                                        for path in &option.0 {
                                            is_equivalent = is_equivalent
                                                && indirect_option.0[0]
                                                    .is_equivalent_save_for_type_explosion_to(
                                                        path,
                                                    )?;
                                        }
                                        if !is_equivalent {
                                            new_options.push(option)
                                        }
                                    }
                                    options = new_options;
                                }
                            }
                        }
                        options.extend(advance_options);
                    }
                }
            }

            // If we were entering a @defer, we've skipped the potential "direct" options because we
            // need an "indirect" one (a key/root query) to be able to actually defer. But in rare
            // cases, it's possible we actually couldn't resolve the key fields needed to take a key
            // but could still find a direct path. If so, it means it's a corner case where we
            // cannot do query-planner-based-@defer and have to fall back on not deferring.
            if options.is_empty() && should_reenter_subgraph {
                let (advance_options, _) = path.advance_with_operation_element(
                    supergraph_schema.clone(),
                    operation_element,
                    &updated_context,
                    condition_resolver,
                )?;
                options = advance_options.unwrap_or_else(Vec::new);
            }

            // At this point, if options is empty, it means we found no ways to advance the
            // operation element for this path, so we should return `None`.
            if options.is_empty() {
                return Ok(None);
            } else {
                options_for_each_path.push(options);
            }
        }

        let all_options = SimultaneousPaths::flat_cartesian_product(options_for_each_path);
        Ok(Some(self.create_lazy_options(all_options, updated_context)))
    }
}

// PORT_NOTE: JS passes a ConditionResolver here, we do not: see port note for
// `SimultaneousPathsWithLazyIndirectPaths`
// TODO(@goto-bus-stop): JS passes `override_conditions` here and maintains stores
// references to it in the created paths. AFAICT override conditions
// are shared mutable state among different query graphs, so having references to
// it in many structures would require synchronization. We should likely pass it as
// an argument to exactly the functionality that uses it.
pub fn create_initial_options(
    initial_path: GraphPath<OpGraphPathTrigger, Option<EdgeIndex>>,
    initial_type: &QueryGraphNodeType,
    initial_context: OpGraphPathContext,
    condition_resolver: &mut impl ConditionResolver,
    excluded_edges: ExcludedDestinations,
    excluded_conditions: ExcludedConditions,
) -> Result<Vec<SimultaneousPathsWithLazyIndirectPaths>, FederationError> {
    let initial_paths = SimultaneousPaths::from(initial_path);
    let mut lazy_initial_path = SimultaneousPathsWithLazyIndirectPaths::new(
        initial_paths,
        initial_context.clone(),
        excluded_edges,
        excluded_conditions,
    );

    if initial_type.is_federated_root_type() {
        let initial_options =
            lazy_initial_path.indirect_options(&initial_context, 0, condition_resolver)?;
        let options = initial_options
            .paths
            .iter()
            .cloned()
            .map(SimultaneousPaths::from)
            .collect();
        Ok(lazy_initial_path.create_lazy_options(options, initial_context))
    } else {
        Ok(vec![lazy_initial_path])
    }
}

impl ClosedBranch {
    /// This method is called on a closed branch (i.e. on all the possible options found to get a
    /// particular leaf of the query being planned), and when there is more than one option, it
    /// tries a last effort at checking an option can be shown to be less efficient than another one
    /// _whatever the rest of the query plan is_ (that is, whatever the options for any other leaf
    /// of the query are).
    ///
    /// In practice, this compares all pairs of options and calls the heuristics of
    /// `compare_options_complexity_out_of_context()` on them to see if one strictly subsumes the
    /// other (and if that's the case, the subsumed one is ignored).
    pub(crate) fn maybe_eliminate_strictly_more_costly_paths(
        self,
    ) -> Result<ClosedBranch, FederationError> {
        if self.0.len() <= 1 {
            return Ok(self);
        }

        // Keep track of which options should be kept.
        let mut keep_options = vec![true; self.0.len()];
        for option_index in 0..(self.0.len()) {
            if !keep_options[option_index] {
                continue;
            }
            // We compare the current option to every other remaining option.
            //
            // PORT_NOTE: We don't technically need to iterate in reverse order here, but the JS
            // codebase does, and we do the same to ensure the result is the same. (The JS codebase
            // requires this because it removes from the array it's iterating through.)
            let option = &self.0[option_index];
            let mut keep_option = true;
            for (other_option, keep_other_option) in self.0[(option_index + 1)..]
                .iter()
                .zip(&mut keep_options[(option_index + 1)..])
                .rev()
            {
                if !*keep_other_option {
                    continue;
                }
                match option
                    .paths
                    .compare_options_complexity_out_of_context(&other_option.paths)?
                {
                    Ordering::Less => {
                        *keep_other_option = false;
                    }
                    Ordering::Equal => {}
                    Ordering::Greater => {
                        keep_option = false;
                        break;
                    }
                }
            }
            if !keep_option {
                keep_options[option_index] = false;
            }
        }

        Ok(ClosedBranch(
            self.0
                .into_iter()
                .zip(&keep_options)
                .filter(|(_, &keep_option)| keep_option)
                .map(|(option, _)| option)
                .collect(),
        ))
    }
}

impl OpPath {
    pub fn len(&self) -> usize {
        self.0.len()
    }

    pub(crate) fn is_empty(&self) -> bool {
        self.0.is_empty()
    }

    pub(crate) fn strip_prefix(&self, maybe_prefix: &Self) -> Option<Self> {
        self.0
            .strip_prefix(&*maybe_prefix.0)
            .map(|slice| Self(slice.to_vec()))
    }

    pub(crate) fn with_pushed(&self, element: Arc<OpPathElement>) -> Self {
        let mut new = self.0.clone();
        new.push(element);
        Self(new)
    }

    pub(crate) fn conditional_directives(&self) -> DirectiveList {
        DirectiveList(
            self.0
                .iter()
                .flat_map(|path_element| {
                    path_element
                        .directives()
                        .iter()
                        .filter(|d| d.name == "include" || d.name == "skip")
                })
                .cloned()
                .collect(),
        )
    }

    /// Filter any fragment element in the provided path whose type condition does not exist in the provided schema.
    /// Not that if the fragment element should be filtered but it has applied directives, then we preserve those applications by
    /// replacing with a fragment with no condition (but if there are no directive, we simply remove the fragment from the path).
    // JS PORT NOTE: this method was called filterOperationPath in JS codebase
    pub(crate) fn filter_on_schema(&self, schema: &ValidFederationSchema) -> OpPath {
        let mut filtered: Vec<Arc<OpPathElement>> = vec![];
        for element in &self.0 {
            match element.as_ref() {
                OpPathElement::InlineFragment(fragment) => {
                    if let Some(type_condition) = &fragment.data().type_condition_position {
                        if schema.get_type(type_condition.type_name().clone()).is_ok() {
                            let updated_fragment = fragment.with_updated_type_condition(None);
                            filtered
                                .push(Arc::new(OpPathElement::InlineFragment(updated_fragment)));
                        } else {
                            continue;
                        }
                    } else {
                        filtered.push(element.clone());
                    }
                }
                _ => {
                    filtered.push(element.clone());
                }
            }
        }
        OpPath(filtered)
    }

    pub(crate) fn has_only_fragments(&self) -> bool {
        // JS PORT NOTE: this was checking for FragmentElement which was used for both inline fragments and spreads
        self.0
            .iter()
            .all(|p| matches!(p.as_ref(), OpPathElement::InlineFragment(_)))
    }
}

impl TryFrom<&'_ OpPath> for Vec<QueryPathElement> {
    type Error = FederationError;

    fn try_from(value: &'_ OpPath) -> Result<Self, Self::Error> {
        value
            .0
            .iter()
            .map(|path_element| {
                Ok(match path_element.as_ref() {
                    OpPathElement::Field(field) => QueryPathElement::Field(field.try_into()?),
                    OpPathElement::InlineFragment(inline) => {
                        QueryPathElement::InlineFragment(inline.try_into()?)
                    }
                })
            })
            .collect()
    }
}

pub(crate) fn concat_paths_in_parents(
    first: &Option<Arc<OpPath>>,
    second: &Option<Arc<OpPath>>,
) -> Option<Arc<OpPath>> {
    if let (Some(first), Some(second)) = (first, second) {
        Some(Arc::new(concat_op_paths(first.deref(), second.deref())))
    } else {
        None
    }
}

pub(crate) fn concat_op_paths(head: &OpPath, tail: &OpPath) -> OpPath {
    // While this is mainly a simple array concatenation, we optimize slightly by recognizing if the
    // tail path starts by a fragment selection that is useless given the end of the head path
    let Some(last_of_head) = head.last() else {
        return tail.clone();
    };
    let mut result = head.clone();
    if tail.is_empty() {
        return result;
    }
    let conditionals = head.conditional_directives();
    let tail_path = tail.0.clone();

    // Note that in practice, we may be able to eliminate a few elements at the beginning of the path
    // due do conditionals ('@skip' and '@include'). Indeed, a (tail) path crossing multiple conditions
    // may start with: [ ... on X @include(if: $c1), ... on X @skip(if: $c2), (...)], but if `head`
    // already ends on type `X` _and_ both the conditions on `$c1` and `$c2` are already found on `head`,
    // then we can remove both fragments in `tail`.
    let mut tail_iter = tail_path.iter();
    for tail_node in &mut tail_iter {
        if !is_useless_followup_element(last_of_head, tail_node, &conditionals)
            .is_ok_and(|is_useless| is_useless)
        {
            result.0.push(tail_node.clone());
            break;
        }
    }
    result.0.extend(tail_iter.cloned());
    result
}

fn is_useless_followup_element(
    first: &OpPathElement,
    followup: &OpPathElement,
    conditionals: &DirectiveList,
) -> Result<bool, FederationError> {
    let type_of_first: Option<CompositeTypeDefinitionPosition> = match first {
        OpPathElement::Field(field) => Some(field.data().output_base_type()?.try_into()?),
        OpPathElement::InlineFragment(fragment) => fragment.data().type_condition_position.clone(),
    };

    let Some(type_of_first) = type_of_first else {
        return Ok(false);
    };

    // The followup is useless if it's a fragment (with no directives we would want to preserve) whose type
    // is already that of the first element (or a supertype).
    return match followup {
        OpPathElement::Field(_) => Ok(false),
        OpPathElement::InlineFragment(fragment) => {
            let Some(type_of_second) = fragment.data().type_condition_position.clone() else {
                return Ok(false);
            };

            let are_useless_directives = fragment.data().directives.is_empty()
                || fragment
                    .data()
                    .directives
                    .iter()
                    .any(|d| !conditionals.contains(d));
            let is_same_type = type_of_first.type_name() == type_of_second.type_name();
            let is_subtype = first
                .schema()
                .schema()
                .is_subtype(type_of_first.type_name(), type_of_second.type_name());
            Ok(are_useless_directives && (is_same_type || is_subtype))
        }
    };
}

#[cfg(test)]
mod tests {
    use std::sync::Arc;

    use apollo_compiler::executable::DirectiveList;
    use apollo_compiler::schema::Name;
    use apollo_compiler::NodeStr;
    use apollo_compiler::Schema;
    use petgraph::stable_graph::EdgeIndex;
    use petgraph::stable_graph::NodeIndex;

    use crate::query_graph::build_query_graph::build_query_graph;
    use crate::query_graph::condition_resolver::ConditionResolution;
    use crate::query_graph::graph_path::OpGraphPath;
    use crate::query_graph::graph_path::OpGraphPathTrigger;
    use crate::query_graph::graph_path::OpPathElement;
    use crate::query_plan::operation::Field;
    use crate::query_plan::operation::FieldData;
    use crate::schema::position::FieldDefinitionPosition;
    use crate::schema::position::ObjectFieldDefinitionPosition;
    use crate::schema::ValidFederationSchema;

    #[test]
    fn path_display() {
        let src = r#"
       type Query
       {
          t: T
       }

       type T
       {
          otherId: ID!
          id: ID!
       }
        "#;
        let schema = Schema::parse_and_validate(src, "./").unwrap();
        let schema = ValidFederationSchema::new(schema).unwrap();
        let name = NodeStr::new("S1");
        let graph = build_query_graph(name, schema.clone()).unwrap();
        let path = OpGraphPath::new(Arc::new(graph), NodeIndex::new(0)).unwrap();
        assert_eq!(path.to_string(), "_");
        let pos = ObjectFieldDefinitionPosition {
            type_name: Name::new("T").unwrap(),
            field_name: Name::new("t").unwrap(),
        };
        let data = FieldData {
            schema: schema.clone(),
            field_position: FieldDefinitionPosition::Object(pos),
            alias: None,
            arguments: Arc::new(Vec::new()),
            directives: Arc::new(DirectiveList::new()),
            sibling_typename: None,
        };
        let trigger = OpGraphPathTrigger::OpPathElement(OpPathElement::Field(Field::new(data)));
        let path = path
            .add(
                trigger,
                Some(EdgeIndex::new(3)),
                ConditionResolution::Satisfied {
                    cost: 0,
                    path_tree: None,
                },
                None,
            )
            .unwrap();
        assert_eq!(path.to_string(), "Query(S1)* --[t]--> T(S1) (types: [T])");
        let pos = ObjectFieldDefinitionPosition {
            type_name: Name::new("ID").unwrap(),
            field_name: Name::new("id").unwrap(),
        };
        let data = FieldData {
            schema,
            field_position: FieldDefinitionPosition::Object(pos),
            alias: None,
            arguments: Arc::new(Vec::new()),
            directives: Arc::new(DirectiveList::new()),
            sibling_typename: None,
        };
        let trigger = OpGraphPathTrigger::OpPathElement(OpPathElement::Field(Field::new(data)));
        let path = path
            .add(
                trigger,
                Some(EdgeIndex::new(1)),
                ConditionResolution::Satisfied {
                    cost: 0,
                    path_tree: None,
                },
                None,
            )
            .unwrap();
        assert_eq!(
            path.to_string(),
            "Query(S1)* --[t]--> T(S1) --[id]--> ID(S1)"
        );
    }
}
